{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc3a70d0",
   "metadata": {},
   "source": [
    "# Environment Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aecf789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/TumorTracer'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Loading environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Changing directory to main directory for easy data access\n",
    "working_directory = os.getenv(\"WORKING_DIRECTORY\")\n",
    "os.chdir(working_directory)\n",
    "\n",
    "# Checking the change\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc911ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git folder exists: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Checking the change\n",
    "print(\"Git folder exists:\", Path(\".git\").exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a926d5",
   "metadata": {},
   "source": [
    "# 1. Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71c7c7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from cnnClassifier import get_logger\n",
    "\n",
    "logger = get_logger()\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    \"\"\"\n",
    "    Immutable configuration class to hold all necessary paths \n",
    "    and dataset identifiers required for the data ingestion stage.\n",
    "    \"\"\"\n",
    "    root_dir: Path          # Base directory for all ingestion outputs\n",
    "    kaggle_dataset: str     # The Kaggle dataset identifier \"owner/dataset\"\n",
    "    download_zip: Path      # Path where the downloaded ZIP file will be saved\n",
    "    extracted_file: Path    # Path where the final extracted file will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0233841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self, config_file_path=CONFIG_FILE_PATH, params_file_path=PARAMS_FILE_PATH) -> None:\n",
    "        \"\"\"\n",
    "        Reads configuration files (config.yaml and params.yaml), \n",
    "        ensures necessary directories exist, and prepares structured config objects.\n",
    "        \"\"\"\n",
    "        # Load both config and params YAML files into memory\n",
    "        if not Path(config_file_path):\n",
    "            logger.error(f\"Config file not found at: {config_file_path}\")\n",
    "            raise FileNotFoundError(f\"Config file not found at: {config_file_path}\")\n",
    "        else:\n",
    "            self.config = read_yaml(config_file_path)\n",
    "\n",
    "        if not Path(config_file_path):\n",
    "            logger.error(f\"Params file not found at: {params_file_path}\")\n",
    "            raise FileNotFoundError(f\"Params file not found at: {params_file_path}\")\n",
    "        else:\n",
    "            self.params = read_yaml(params_file_path)\n",
    "\n",
    "        logger.info(f\"Loading configuration from {config_file_path} and parameters from {params_file_path}\")\n",
    "\n",
    "        # Create the root artifacts directory (if not already present)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_ingestion_config(self) -> DataIngestionConfig:\n",
    "        \"\"\"\n",
    "        Creates and returns a DataIngestionConfig object with paths defined \n",
    "        for downloading and extracting the dataset.\n",
    "        \n",
    "        Returns:\n",
    "        - DataIngestionConfig: Structured config object for ingestion stage.\n",
    "        \"\"\"\n",
    "        config = self.config.data_ingestion\n",
    "\n",
    "        # Ensure the data_ingestion directory exists\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        # Build and return a structured configuration object for ingestion\n",
    "        ingestion_config = DataIngestionConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            kaggle_dataset=config.kaggle_dataset,\n",
    "            download_zip=Path(config.download_zip),\n",
    "            extracted_file=Path(config.extracted_file),\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"DataIngestionConfig created with: {ingestion_config}\")\n",
    "\n",
    "        return ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d04271fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-30 19:48:38,827: INFO: common: Directory: /home/codespace/.kaggle created successfully.]\n",
      "[2025-06-30 19:48:38,828: INFO: common: Directory: /home/codespace/.kaggle created successfully.]\n",
      "[2025-06-30 19:48:38,829: INFO: common: JSON file saved at: /home/codespace/.kaggle/kaggle.json]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from cnnClassifier.utils.common import create_directories, save_json\n",
    "\n",
    "def setup_kaggle_auth_from_secret(secret_env_var: str = \"KAGGLE_JSON\") -> None:\n",
    "    \"\"\"\n",
    "    Sets up Kaggle API authentication using a secret stored in an environment variable.\n",
    "\n",
    "    Parameters:\n",
    "    - secret_env_var (str): The name of the environment variable that contains\n",
    "                            the Kaggle credentials as a JSON string.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If the environment variable is missing or contains invalid JSON.\n",
    "    - Exception: For any other unhandled errors.\n",
    "    \"\"\"\n",
    "    # Read from environment variable (injected from Codespaces secret)\n",
    "    kaggle_json_str = os.getenv(secret_env_var)\n",
    "\n",
    "    if kaggle_json_str is None:\n",
    "        raise ValueError(f\"{secret_env_var} secret not found.\")\n",
    "    \n",
    "    try:\n",
    "        # Validate it's a proper JSON\n",
    "        kaggle_json_data = json.loads(kaggle_json_str)\n",
    "    except json.JSONDecodeError as exception:\n",
    "        raise ValueError(f\"{secret_env_var} does not contain valid JSON: {exception}\")\n",
    "\n",
    "    # Setting directory path\n",
    "    kaggle_dir = Path.home() / \".kaggle\"\n",
    "    kaggle_json_path = kaggle_dir / \"kaggle.json\"\n",
    "\n",
    "    try:\n",
    "        create_directories([kaggle_dir])\n",
    "        save_json(kaggle_json_path, kaggle_json_data)\n",
    "\n",
    "        # Set permissions\n",
    "        os.chmod(kaggle_json_path, 0o600)\n",
    "\n",
    "        # Set the environment variable explicitly for kaggle to pick up\n",
    "        os.environ[\"KAGGLE_CONFIG_DIR\"] = str(kaggle_dir)\n",
    "    \n",
    "    except Exception as exception:\n",
    "        raise exception\n",
    "    \n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "setup_kaggle_auth_from_secret()\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bbffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "import zipfile\n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def download_files(self) -> None:\n",
    "        \"\"\"\n",
    "        Downloads dataset from Kaggle using kaggle API.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            kaggle.api.dataset_download_files(\n",
    "                dataset=self.config.kaggle_dataset,\n",
    "                path=self.config.root_dir,\n",
    "                unzip=False\n",
    "            )\n",
    "\n",
    "            logger.info(f\"Successfully downloaded dataset {self.config.kaggle_dataset} at: {self.config.root_dir}\")\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error file downloading dataset: {exception_error}\")\n",
    "            raise exception_error\n",
    "\n",
    "    def extract_files(self) -> None:\n",
    "        \"\"\"\n",
    "        Extracts the downloaded ZIP file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with zipfile.ZipFile(self.config.download_zip, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(self.config.root_dir)\n",
    "                logger.info(f\"Successfully extracted dataset {self.config.kaggle_dataset} at: {self.config.extracted_file}\")\n",
    "\n",
    "            if not self.config.extracted_file.exists():\n",
    "                logger.warning(f\"Expected file not found after extraction: {self.config.extracted_file}\")\n",
    "\n",
    "        except zipfile.BadZipFile:\n",
    "            logger.error(f\"Invalid zip file format.\")\n",
    "        \n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error file unziping dataset: {exception_error}\")\n",
    "            raise exception_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1307a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-30 19:48:38,853: INFO: common: YAML file: config/config.yaml loaded successfully]\n",
      "[2025-06-30 19:48:38,855: INFO: common: YAML file: params.yaml loaded successfully]\n",
      "[2025-06-30 19:48:38,856: INFO: 485166113: Loading configuration from config/config.yaml and parameters from params.yaml]\n",
      "[2025-06-30 19:48:38,857: INFO: common: Directory: artifacts created successfully.]\n",
      "[2025-06-30 19:48:38,858: INFO: common: Directory: artifacts/data_ingestion created successfully.]\n",
      "[2025-06-30 19:48:38,859: INFO: 485166113: DataIngestionConfig created with: DataIngestionConfig(root_dir=PosixPath('artifacts/data_ingestion'), kaggle_dataset='mohamedhanyyy/chest-ctscan-images', download_zip=PosixPath('artifacts/data_ingestion/chest-ctscan-images.zip'), extracted_file=PosixPath('artifacts/data_ingestion/Data'))]\n",
      "Dataset URL: https://www.kaggle.com/datasets/mohamedhanyyy/chest-ctscan-images\n",
      "[2025-06-30 19:48:48,952: INFO: 2954299612: Successfully downloaded dataset mohamedhanyyy/chest-ctscan-images at: artifacts/data_ingestion]\n",
      "[2025-06-30 19:48:50,011: INFO: 2954299612: Successfully extracted dataset mohamedhanyyy/chest-ctscan-images at: artifacts/data_ingestion/Data]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config_manager = ConfigurationManager()\n",
    "    ingestion_config = config_manager.get_ingestion_config()\n",
    "\n",
    "    data_ingestor = DataIngestion(config=ingestion_config)\n",
    "    data_ingestor.download_files()\n",
    "    data_ingestor.extract_files()\n",
    "\n",
    "except Exception as exception:\n",
    "    logger.exception(f\"Unexpected error during data ingestion pipeline: {exception}\")\n",
    "    raise exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729f881e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
