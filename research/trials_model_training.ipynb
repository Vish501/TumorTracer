{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df151a0",
   "metadata": {},
   "source": [
    "# Environment Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "439fb644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/TumorTracer'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Loading environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Changing directory to main directory for easy data access\n",
    "working_directory = os.getenv(\"WORKING_DIRECTORY\")\n",
    "os.chdir(working_directory)\n",
    "\n",
    "# Checking the change\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a2b2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git folder exists: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Checking the change\n",
    "print(\"Git folder exists:\", Path(\".git\").exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e77ad8",
   "metadata": {},
   "source": [
    "# 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8554ae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from cnnClassifier import get_logger\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "# Initializing the logger\n",
    "logger = get_logger()\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainingConfig:\n",
    "    \"\"\"\n",
    "    Immutable configuration class to store all parameters \n",
    "    and paths required for model training. \n",
    "    \"\"\"\n",
    "    root_dir: Path                                          # Directory for training artifacts\n",
    "    trained_model_path: Path                                # Final model output path\n",
    "    updated_base_model: Path                                # Pretrained model with custom head\n",
    "    training_data: Path                                     # Directory with training images\n",
    "    validation_data: Path                                   # Directory with validation images\n",
    "    params_augmentation: bool                               # Whether to apply augmentation\n",
    "    params_checkpoint: bool                                 # Whether created models need to be checkpointed\n",
    "    params_mlflow: bool                                     # Whether models need to be tracker in mlflow\n",
    "    params_image_size: tuple[int, int, int]                 # Input image size, e.g., [224, 224, 3]\n",
    "    params_batch_size: int                                  # Batch size for training\n",
    "    params_epochs: int                                      # Total epochs\n",
    "    params_optimizer: str                                   # Optimizer to be used when recompling model\n",
    "    params_learning_rate: float                             # Learning rate for training\n",
    "    params_if_augmentation: Optional[Dict[str, Any]] = None # Dict of augmentation hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d3dd096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories\n",
    "from cnnClassifier import get_logger\n",
    "\n",
    "# Initializing the logger\n",
    "logger = get_logger()\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self, config_file_path=CONFIG_FILE_PATH, params_file_path=PARAMS_FILE_PATH) -> None:\n",
    "        \"\"\"\n",
    "        Reads configuration files (config.yaml and params.yaml), \n",
    "        ensures necessary directories exist, and prepares structured config objects.\n",
    "\n",
    "        Args:\n",
    "        - config_file_path (str): Path to the config.yaml file.\n",
    "        - params_file_path (str): Path to the params.yaml file.\n",
    "        \"\"\"\n",
    "        # Validate and load config.yaml\n",
    "        if not Path(config_file_path).exists():\n",
    "            logger.error(f\"Config file not found at: {config_file_path}\")\n",
    "            raise FileNotFoundError(f\"Config file not found at: {config_file_path}\")\n",
    "        self.config = read_yaml(config_file_path)\n",
    "\n",
    "        # Validate and load params.yaml\n",
    "        if not Path(config_file_path).exists():\n",
    "            logger.error(f\"Params file not found at: {params_file_path}\")\n",
    "            raise FileNotFoundError(f\"Params file not found at: {params_file_path}\")\n",
    "        self.params = read_yaml(params_file_path)\n",
    "\n",
    "        logger.info(f\"Loading configuration from {config_file_path} and parameters from {params_file_path}\")\n",
    "\n",
    "        # Create the root artifacts directory (if not already present)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_training_config(self) -> ModelTrainingConfig:\n",
    "        \"\"\"\n",
    "        Prepares and returns the ModelTrainingConfig object.\n",
    "\n",
    "        Returns:\n",
    "        - ModelTrainingConfig: Structured config for training the updated base model.\n",
    "        \"\"\"\n",
    "        training_config = self.config.model_training\n",
    "        training_params = self.params.model_training\n",
    "\n",
    "        # Ensure the data_ingestion directory exists\n",
    "        create_directories([training_config.root_dir])\n",
    "\n",
    "        # Load augmentation params only if augmentation is enabled and params for it are present\n",
    "        params_for_augmentation = {}\n",
    "        if training_params.AUGMENTATION and hasattr(training_params, \"AUGMENTATION_PARAMS\"):\n",
    "            params_for_augmentation = dict(training_params.AUGMENTATION_PARAMS )\n",
    "\n",
    "        training_config = ModelTrainingConfig(\n",
    "            root_dir=Path(training_config.root_dir),\n",
    "            trained_model_path=Path(training_config.trained_model_path),\n",
    "            updated_base_model=Path(training_config.updated_model_path),\n",
    "            training_data=Path(training_config.training_dataset),\n",
    "            validation_data=Path(training_config.validation_dataset),\n",
    "            params_augmentation=training_params.AUGMENTATION,\n",
    "            params_checkpoint=training_params.CHECKPOINT,\n",
    "            params_mlflow=training_params.MLFLOW_TRACKING,\n",
    "            params_image_size=tuple(training_params.IMAGE_SIZE),\n",
    "            params_batch_size=training_params.BATCH_SIZE,\n",
    "            params_epochs=training_params.EPOCHS,\n",
    "            params_optimizer=training_params.OPTIMIZER,\n",
    "            params_learning_rate=training_params.LEARNING_RATE,\n",
    "            params_if_augmentation=params_for_augmentation,\n",
    "        )\n",
    "\n",
    "        logger.info(f\"ModelTrainingConfig created with: {training_config}\")\n",
    "\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81607de",
   "metadata": {},
   "source": [
    "## Version 1 - Manually created callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a4f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from math import ceil\n",
    "from typing import Union\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, DirectoryIterator # type: ignore\n",
    "from pathlib import Path\n",
    "from dataclasses import asdict\n",
    "from datetime import datetime\n",
    "\n",
    "from cnnClassifier.utils.common import create_directories, save_json\n",
    "from cnnClassifier import get_logger\n",
    "\n",
    "# Initializing the logger\n",
    "logger = get_logger()\n",
    "\n",
    "class ModelTraining:\n",
    "    \"\"\"\n",
    "    Initializes training pipeline with given configuration.\n",
    "\n",
    "    Core Responsibilities:\n",
    "    - Load a pre-defined base model from disk and recompile it with a fresh optimizer.\n",
    "    - Set up data generators for training and validation, with optional augmentation.\n",
    "    - Train the model across multiple epochs with optional checkpointing.\n",
    "    - Resume training from where it left off.\n",
    "    - Save class label mappings and model artifacts.\n",
    "\n",
    "    Public Methods:\n",
    "    - get_base_model(): Load and compile the pre-trained base model.\n",
    "    - get_data_generators(): Prepare train and validation data generators.\n",
    "    - train(): Train the model with checkpointing on best validation accuracy.\n",
    "    - resume_train(add_epochs): Continue training the model for additional epochs.\n",
    "    - save_class_indices(): Save class-to-index mapping as JSON for reproducibility.\n",
    "\n",
    "    Private Utilities:\n",
    "    - _build_generator(): Helper to construct data generators with standard settings.\n",
    "    - _create_checkpoint(): Creates a checkpoint directory and stores training metadata.\n",
    "    - _get_optimizer(): Returns optimizer based on config.\n",
    "    - _count_images_in_directory(): Utility to count image files recursively.\n",
    "    - _save_model(): Saves the model to disk at the given path.\n",
    "    \"\"\"\n",
    "    def __init__(self, config: ModelTrainingConfig) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the model training pipeline.\n",
    "\n",
    "        - Sets random seeds for reproducibility.\n",
    "        - Prepares internal attributes for managing training, checkpoints, and model state.\n",
    "        \"\"\"\n",
    "        # Store configuration\n",
    "        self.config = config\n",
    "\n",
    "        # Set random seeds\n",
    "        seed = self.config.params_seed if hasattr(self.config, \"params_seed\") else 1234\n",
    "        tf.random.set_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        # Initialize model and training attributes\n",
    "        self.output_model = None\n",
    "        self.training_generator = None\n",
    "        self.valid_generator = None\n",
    "        self.training_images = None\n",
    "        self.validation_images = None\n",
    "        self.last_epoch = 0\n",
    "        self.additional_epochs = 0\n",
    "        self.best_val_accuracy = 0\n",
    "\n",
    "        # Initialize checkpoint directory path with timestamp\n",
    "        curr_time = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "        self.checkpoint_path = Path(self.config.root_dir / f\"Checkpoint_{curr_time}\")\n",
    "\n",
    "\n",
    "    def get_base_model(self) -> None:\n",
    "        \"\"\"\n",
    "        Loads the base model form specified path.\n",
    "        \"\"\"\n",
    "        model_path = Path(self.config.updated_base_model)\n",
    "\n",
    "        if not model_path.exists():\n",
    "            logger.error(f\"Could not find model at {model_path}. Run the Base Model pipeline stage first.\")\n",
    "            raise FileNotFoundError(f\"Could not find model at {model_path}. Run the Base Model pipeline stage first.\")\n",
    "        \n",
    "        try:\n",
    "            self.output_model = tf.keras.models.load_model(model_path)\n",
    "            logger.info(f\"Successfully loaded the base model from {model_path}.\")\n",
    "\n",
    "            # Enabling Eager Execution (optional in TF 2.x) due to library requirement\n",
    "            tf.config.run_functions_eagerly(True)\n",
    "\n",
    "            # Recompile model with a fresh optimizer (required after loading)\n",
    "            self.output_model.compile(\n",
    "                optimizer=self._get_optimizer(),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                metrics=[\"accuracy\"]\n",
    "            )\n",
    "            logger.info(f\"Successfully recomplied the model.\")\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while loading the update base model at {model_path}: {exception_error}\")\n",
    "            raise \n",
    "            \n",
    "    \n",
    "    def get_data_generators(self) -> None:\n",
    "        \"\"\"\n",
    "        Update train and validation data generators using ImageDataGenerator.\n",
    "        Applies augmentation only on training data if enabled.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(\"Preparing ImageDataGenerators...\")\n",
    "\n",
    "            train_datagen = ImageDataGenerator(rescale=1.0/255, **self.config.params_if_augmentation)\n",
    "            valid_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "            self.training_generator = self._build_generator(train_datagen, self.config.training_data, \"Train\")\n",
    "            self.valid_generator = self._build_generator(valid_datagen, self.config.validation_data, \"Valid\")\n",
    "\n",
    "            # Ensure class-to-index mapping is consistent\n",
    "            if self.training_generator.class_indices != self.valid_generator.class_indices:\n",
    "                logger.error(\"Mismatch in class indices between train and validation generators!\")\n",
    "                raise ValueError(\"Mismatch in class indices between train and validation generators!\")\n",
    "\n",
    "            logger.info(\"ImageDataGenerators created successfully.\")\n",
    "        \n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while creating data generators: {exception_error}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def train(self) -> None:\n",
    "        \"\"\"\n",
    "        Trains the model using prepared generators.\n",
    "        \"\"\"\n",
    "        if self.output_model == None:\n",
    "            logger.error(\"Base model not found. Run get_base_model() before calling train().\")\n",
    "            raise ValueError(\"Base model not found. Run get_base_model() before calling train().\")\n",
    "        \n",
    "        if (self.config.params_checkpoint) and (not self.checkpoint_path.exists()) and (self.config.params_epochs >= 1):\n",
    "            self._create_checkpoint()\n",
    "        \n",
    "        try:\n",
    "            logger.info(\"Initializing model training...\")\n",
    "\n",
    "            # Counting the images in each of the datasets\n",
    "            self.training_images = self._count_images_in_directory(self.config.training_data)\n",
    "            self.validation_images = self._count_images_in_directory(self.config.validation_data)\n",
    "            \n",
    "            # Fitting the model\n",
    "            for epoch in range(self.last_epoch, self.config.params_epochs + self.additional_epochs):\n",
    "                history = self.output_model.fit(\n",
    "                    self.training_generator,\n",
    "                    validation_data=self.valid_generator,\n",
    "                    initial_epoch=epoch,         # Sets starting point for correct logging\n",
    "                    epochs=epoch+1,              # Only running 1 epoch at a time\n",
    "                    steps_per_epoch=ceil(self.training_images / self.config.params_batch_size),\n",
    "                    validation_steps=ceil(self.validation_images / self.config.params_batch_size),\n",
    "                )\n",
    "\n",
    "                # Updating number of epochs completed\n",
    "                self.last_epoch = epoch\n",
    "\n",
    "                if self.config.params_checkpoint:\n",
    "                    # Accessing accurary scores\n",
    "                    train_acc = history.history.get(\"accuracy\", [0])[0]\n",
    "                    val_acc = history.history.get(\"val_accuracy\", [0])[0]\n",
    "\n",
    "                    # If current model is better than prior best model, saving the model\n",
    "                    if val_acc > self.best_val_accuracy:\n",
    "                        self.best_val_accuracy = val_acc\n",
    "                        model_path = Path(self.checkpoint_path / f\"model_e{epoch+1:02d}_acc{train_acc:.4f}_vacc{val_acc:.4f}.h5\")\n",
    "                        self._save_model(save_path=model_path, model=self.output_model)\n",
    "                        logger.info(f\"Saved new best model at {model_path}\")\n",
    "\n",
    "            logger.info(\"Successfully trained model based on provided parameters.\")\n",
    "            self._save_model(save_path=self.config.trained_model_path, model=self.output_model)\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while training the model: {exception_error}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def resume_train(self, add_epochs: int) -> None:\n",
    "        \"\"\"\n",
    "        Resumes model training for additional number of epochs.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if self.additional_epochs == None:\n",
    "                self.additional_epochs = 0\n",
    "            self.additional_epochs += add_epochs\n",
    "\n",
    "            self.train()\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while resuming training: {exception_error}\")\n",
    "            raise\n",
    "    \n",
    "\n",
    "    def save_class_indices(self) -> None:\n",
    "        \"\"\"\n",
    "        Saves the class index mapping as a JSON file for future reference.\n",
    "        \"\"\"\n",
    "        if self.training_generator == None:\n",
    "            logger.error(\"Class indices not found. Run get_data_generators() before calling save_class_indices().\")\n",
    "            raise ValueError(\"Class indices not found. Run get_data_generators() before calling save_class_indices().\")\n",
    "\n",
    "        try:\n",
    "            save_path = Path(self.config.root_dir / \"class_indices.json\")\n",
    "            save_json(save_path=save_path, data=self.training_generator.class_indices)\n",
    "\n",
    "            if self.config.params_checkpoint and self.checkpoint_path.exists():\n",
    "                checkpoint_save_path = Path(self.checkpoint_path / \"class_indices.json\")\n",
    "                save_json(save_path=checkpoint_save_path, data=self.training_generator.class_indices)\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while saving class indices: {exception_error}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def _build_generator(self, datagen: ImageDataGenerator, data_path: Union[str, Path], tag: str) -> DirectoryIterator:\n",
    "        \"\"\"\n",
    "        Helper to build a flow_from_directory generator with consistent options.\n",
    "\n",
    "        Args:\n",
    "        - datagen (ImageDataGenerator): Instance of the ImageDataGenerator.\n",
    "        - data_path (Union[str, Path]): Path to the directory containing images.\n",
    "        - tag (str): Label for logging context (\"Train\" or \"Valid\").\n",
    "\n",
    "        Returns:\n",
    "        - DirectoryIterator: Configured Keras generator for the given directory.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data_path = Path(data_path)\n",
    "\n",
    "            if not data_path.exists():\n",
    "                logger.error(f\"{tag.title()} directory not found: {data_path}\")\n",
    "                raise FileNotFoundError(f\"{tag.title()} directory not found: {data_path}\")\n",
    "\n",
    "            # Building generator\n",
    "            generator_unit = datagen.flow_from_directory(\n",
    "                directory=data_path,\n",
    "                target_size=self.config.params_image_size[:2],\n",
    "                batch_size=self.config.params_batch_size,\n",
    "                class_mode=\"categorical\",\n",
    "                shuffle=True,\n",
    "            )\n",
    "\n",
    "            return generator_unit\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while build generator: {exception_error}\")\n",
    "            raise\n",
    "    \n",
    "\n",
    "    def _create_checkpoint(self) -> None:\n",
    "        \"\"\"\n",
    "        Creates a checkpoint directory and saves the training configuration as a JSON file.\n",
    "\n",
    "        Purpose:\n",
    "        - Ensures the checkpoint directory exists.\n",
    "        - Saves the current training configuration (hyperparameters) used in that run.\n",
    "        - Helps with reproducibility and traceability for saved models.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(\"Creating checkpoint directory...\")\n",
    "\n",
    "            save_path = Path(self.checkpoint_path / \"params_used.json\")\n",
    "            create_directories([self.checkpoint_path])\n",
    "\n",
    "            # Convert all Path objects to str recursively\n",
    "            config_dict = self._convert_paths_to_str(asdict(self.config))\n",
    "\n",
    "            save_json(save_path=save_path, data=config_dict)\n",
    "            \n",
    "            logger.info(f\"Checkpoint directory created.\")\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while creating checkpoint directroy: {exception_error}\")\n",
    "            raise \n",
    "\n",
    "\n",
    "    def _get_optimizer(self) -> tf.keras.optimizers.Optimizer:\n",
    "        \"\"\"\n",
    "        Dynamically selects and returns a TensorFlow optimizer based on the configuration.\n",
    "\n",
    "        Returns:\n",
    "            tf.keras.optimizers.Optimizer: Configured optimizer instance for model compilation.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Normalize optimizer name to lowercase for consistent matching\n",
    "            optimizer_name = self.config.params_optimizer.strip().upper()\n",
    "            optimizer = None\n",
    "\n",
    "            # Select optimizer based on configuration\n",
    "            if optimizer_name == \"SGD\":\n",
    "                optimizer = tf.keras.optimizers.SGD(learning_rate=self.config.params_learning_rate)\n",
    "\n",
    "            elif optimizer_name == \"RMSPROP\":\n",
    "                optimizer = tf.keras.optimizers.RMSprop(learning_rate=self.config.params_learning_rate) \n",
    "\n",
    "            else:\n",
    "                # Default to Adam if unsupported optimizer name is provided\n",
    "                if optimizer_name != \"ADAM\":\n",
    "                    logger.info(f\"Unsupported optimizer name {optimizer_name} provided. Falling back to 'Adam'.\")\n",
    "                    optimizer_name = \"ADAM\"\n",
    "\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate=self.config.params_learning_rate)\n",
    "\n",
    "            logger.info(f\"Optimizer '{optimizer_name}' initialized and returned.\")\n",
    "            return optimizer\n",
    "        \n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while loading optimizer: {exception_error}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _count_images_in_directory(directory_path: Union[str, Path]) -> int:\n",
    "        \"\"\"\n",
    "        Counts the total number of image files in a directory and its subfolders.\n",
    "\n",
    "        Args:\n",
    "        - directory_path (str or Path): Path to the dataset root (e.g., train or valid)\n",
    "\n",
    "        Returns:\n",
    "        - int: Total number of images found\n",
    "        \"\"\"\n",
    "        try:\n",
    "            directory_path = Path(directory_path)\n",
    "            total_images = 0\n",
    "\n",
    "            if not directory_path.exists():\n",
    "                logger.error(f\"Could not find the path {directory_path}\")\n",
    "                raise FileNotFoundError(f\"Could not find the path {directory_path}\")\n",
    "            \n",
    "            for _, _, files in os.walk(directory_path):\n",
    "                total_images += len([f for f in files if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
    "\n",
    "            if total_images == 0:\n",
    "                logger.error(f\"No images found in {directory_path}\")\n",
    "                raise ValueError(f\"No images found in {directory_path}\")       \n",
    "\n",
    "            return total_images\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while counting images in directory: {exception_error}\")\n",
    "            raise\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def _convert_paths_to_str(obj: dict) -> dict:\n",
    "        \"\"\"\n",
    "        Recursively convert Path objects in a nested dictionary to strings.\n",
    "        \"\"\"\n",
    "        output = {}\n",
    "        for key, value in obj.items():\n",
    "            if isinstance(value, Path):\n",
    "                output[key] = str(value)\n",
    "            elif isinstance(value, dict):\n",
    "                output[key] = ModelTraining._convert_paths_to_str(value)\n",
    "            else:\n",
    "                output[key] = value\n",
    "        return output\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _save_model(save_path: Path, model: tf.keras.Model) -> None:\n",
    "        \"\"\"\n",
    "        Saves a given model to the specified path.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            create_directories([save_path.parent])\n",
    "            model.save(save_path)\n",
    "            logger.info(f\"Model saved at: {save_path}\")\n",
    "        \n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while saving the model at {save_path}: {exception_error}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09059d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config_manager = ConfigurationManager()\n",
    "    training_config = config_manager.get_training_config()\n",
    "\n",
    "    training_constructor = ModelTraining(config=training_config)\n",
    "    training_constructor.get_base_model()\n",
    "    training_constructor.get_data_generators()\n",
    "    training_constructor.train()\n",
    "    training_constructor.save_class_indices()\n",
    "    training_constructor.resume_train(add_epochs=1)\n",
    "\n",
    "except Exception as exception_error:\n",
    "    logger.exception(f\"Unexpected error during model training pipeline: {exception_error}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727a36cc",
   "metadata": {},
   "source": [
    "## Version 2 - With custom callback using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3066b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import dagshub\n",
    "import mlflow\n",
    "\n",
    "from math import ceil\n",
    "from typing import Union\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, DirectoryIterator # type: ignore\n",
    "from tensorflow.keras.callbacks import Callback # type: ignore\n",
    "from pathlib import Path\n",
    "from dataclasses import asdict\n",
    "from datetime import datetime\n",
    "\n",
    "from cnnClassifier.utils.common import create_directories, save_json, save_tf_model, convert_paths_to_str\n",
    "from cnnClassifier import get_logger\n",
    "\n",
    "# Initializing the logger\n",
    "logger = get_logger()\n",
    "\n",
    "class CheckpointCallback(Callback):\n",
    "    \"\"\"\n",
    "    A custom Keras callback that saves the model whenever the validation accuracy improves.\n",
    "    The model file name includes the epoch number, training accuracy, and validation accuracy.\n",
    "\n",
    "    Attributes:\n",
    "        save_directory (Path): Directory where the model should be saved.\n",
    "        model (tf.keras.Model): Reference to the model being trained.\n",
    "        best_val_acc (float): Tracks the best validation accuracy seen so far.\n",
    "    \"\"\"\n",
    "    def __init__(self, save_directory: Path, model_to_save: tf.keras.Model) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the callback with directory and model reference.\n",
    "\n",
    "        Args:\n",
    "            save_directory (Path): Where to save the best model checkpoints.\n",
    "            model (tf.keras.Model): The model being trained (required for manual saving).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.best_val_accuracy = 0\n",
    "        self.save_directory = save_directory\n",
    "        self.model_to_save = model_to_save\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch: int, logs: dict[str, float] = None) -> None:\n",
    "        \"\"\"\n",
    "        Called at the end of each epoch. Checks validation accuracy and saves model if improved.\n",
    "\n",
    "        Args:\n",
    "            epoch (int): The index of the current epoch (0-based).\n",
    "            logs (dict[str, float]): Dictionary containing metrics like accuracy, val_accuracy, etc.\n",
    "        \"\"\"\n",
    "        # Validating logs is available\n",
    "        if not logs:\n",
    "            logger.warning(f\"Logs not found. Skipping model save.\")\n",
    "            return\n",
    "\n",
    "        # Getting metrics from logs\n",
    "        val_acc = logs.get(\"val_accuracy\")\n",
    "        train_acc = logs.get(\"accuracy\")\n",
    "\n",
    "        # If validation accuracy isn't available, skip saving\n",
    "        if val_acc is None:\n",
    "            logger.warning(\"val_accuracy not found in logs. Skipping model save.\")\n",
    "            return\n",
    "\n",
    "        # If current model is better than prior best model, saving the model\n",
    "        if val_acc > self.best_val_accuracy:\n",
    "            self.best_val_accuracy = val_acc\n",
    "\n",
    "            # Construct model filename with padded epoch, train_acc, and val_acc\n",
    "            model_path = Path(self.save_directory / f\"model_e{epoch+1:02d}_acc{train_acc:.4f}_vacc{val_acc:.4f}.h5\")\n",
    "\n",
    "            # Save the model to disk\n",
    "            save_tf_model(save_path=model_path, model=self.model_to_save)\n",
    "            logger.info(f\"Saved new best model at {model_path}\")\n",
    "\n",
    "\n",
    "class MLflowCallback(Callback):\n",
    "    \"\"\"\n",
    "    A custom Keras callback that saves the model whenever the validation accuracy improves.\n",
    "    The model file name includes the epoch number, training accuracy, and validation accuracy.\n",
    "    \"\"\"\n",
    "    def __init__(self, config: Optional[dict] = None, checkpoint_path: Path = None) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the callback with directory and model reference.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs: Optional[dict] = None) -> None:\n",
    "        \"\"\"\n",
    "        Called at the beginning of training.\n",
    "        Logs all the parameters to MLflow.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not mlflow.active_run():\n",
    "                logger.error(f\"Unable to find an active MLFlow run.\")\n",
    "                raise ValueError(f\"Unable to find an active MLFlow run.\")\n",
    "\n",
    "            # Flattening config as MLFlow only accepts ints, strs, floats, and such\n",
    "            config_dict = convert_paths_to_str(asdict(self.config))\n",
    "            flatten_config_dict = {}\n",
    "\n",
    "            for key, value in config_dict.items():\n",
    "                if isinstance(value, dict):\n",
    "                    for sub_key, sub_value in value.items():\n",
    "                        flatten_config_dict[f\"{key}.{sub_key}\"] = sub_value\n",
    "                elif isinstance(value, list):\n",
    "                    flatten_config_dict[key] = str(value)\n",
    "                else:\n",
    "                    flatten_config_dict[key] = value\n",
    "\n",
    "            for key, value in flatten_config_dict.items():\n",
    "                mlflow.log_param(key, value)\n",
    "\n",
    "            # Saving checkpoint path\n",
    "            mlflow.log_param(\"Checkpoint Path\", str(self.checkpoint_path))\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while logging params in MLflow: {exception_error}\")\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch: int, logs: dict[str, float] = None) -> None:\n",
    "        \"\"\"\n",
    "        Called at the end of each epoch.\n",
    "        Logs the accuracy metrics and saves the model if val_accuracy improves.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not logs:\n",
    "                logger.warning(f\"Logs not found. Skipping model save to MLflow.\")\n",
    "                return\n",
    "            \n",
    "            # Registering epoch id as a metric\n",
    "            mlflow.log_metric(\"epoch\", epoch + 1, step=epoch)\n",
    "\n",
    "            # Logging all metrics\n",
    "            for key, value in logs.items():\n",
    "                mlflow.log_metric(key, value, step=epoch)\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while logging metrics in MLflow: {exception_error}\")\n",
    "\n",
    "\n",
    "class ModelTraining:\n",
    "    \"\"\"\n",
    "    Initializes training pipeline with given configuration.\n",
    "\n",
    "    Core Responsibilities:\n",
    "    - Load a pre-defined base model from disk and recompile it with a fresh optimizer.\n",
    "    - Set up data generators for training and validation, with optional augmentation.\n",
    "    - Train the model across multiple epochs with optional checkpointing.\n",
    "    - Resume training from where it left off.\n",
    "    - Save class label mappings and model artifacts.\n",
    "\n",
    "    Public Methods:\n",
    "    - get_base_model(): Load and compile the pre-trained base model.\n",
    "    - get_data_generators(): Prepare train and validation data generators.\n",
    "    - train(): Train the model with checkpointing on best validation accuracy.\n",
    "    - resume_train(add_epochs): Continue training the model for additional epochs.\n",
    "    - save_class_indices(): Save class-to-index mapping as JSON for reproducibility.\n",
    "\n",
    "    Private Utilities:\n",
    "    - _build_generator(): Helper to construct data generators with standard settings.\n",
    "    - _get_callbacks(): Constructs and returns a list of Keras-compatible callbacks based on config settings.\n",
    "    - _create_checkpoint(): Creates a checkpoint directory and stores training metadata.\n",
    "    - _get_optimizer(): Returns optimizer based on config.\n",
    "    - _count_images_in_directory(): Utility to count image files recursively.\n",
    "    \"\"\"\n",
    "    def __init__(self, config: ModelTrainingConfig) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the model training pipeline.\n",
    "\n",
    "        - Sets random seeds for reproducibility.\n",
    "        - Prepares internal attributes for managing training, checkpoints, and model state.\n",
    "        \"\"\"\n",
    "        # Store configuration\n",
    "        self.config = config\n",
    "\n",
    "        # Set random seeds\n",
    "        seed = self.config.params_seed if hasattr(self.config, \"params_seed\") else 1234\n",
    "        tf.random.set_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        # Initialize model and training attributes\n",
    "        self.output_model = None\n",
    "        self.training_generator = None\n",
    "        self.valid_generator = None\n",
    "        self.training_images = None\n",
    "        self.validation_images = None\n",
    "        self.last_epoch = 0\n",
    "        self.additional_epochs = 0\n",
    "        self.best_val_accuracy = 0\n",
    "\n",
    "        # Initialize checkpoint directory path with timestamp\n",
    "        self.curr_time = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "        self.checkpoint_path = Path(self.config.root_dir / f\"Checkpoint_{self.curr_time}\")\n",
    "\n",
    "\n",
    "    def __enter__(self) -> None:\n",
    "        \"\"\"\n",
    "        Called when entering the 'with' block.\n",
    "        Starts an MLflow run if enabled in config.\n",
    "\n",
    "        Returns:\n",
    "        - self: The instance of ModelTraining.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if mlflow.active_run():\n",
    "                mlflow.end_run()\n",
    "\n",
    "            if self.config.params_mlflow:\n",
    "                # Start a named MLflow run\n",
    "                with mlflow.start_run(f\"Run:_{self.curr_time}\"):\n",
    "                    logger.info(f\"Initializing MLflow run\")\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while setting up MLFlow: {exception_error}\")\n",
    "            raise\n",
    "        \n",
    "        return self\n",
    "\n",
    "\n",
    "    def __exit__(self) -> None:\n",
    "        \"\"\"\n",
    "        Called when exiting the 'with' block.\n",
    "        Ends the MLflow run if active.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if mlflow.active_run():\n",
    "                mlflow.end_run()\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while stopping MLflow: {exception_error}\")\n",
    "            raise\n",
    " \n",
    "\n",
    "    def get_base_model(self) -> None:\n",
    "        \"\"\"\n",
    "        Loads the base model form specified path.\n",
    "        \"\"\"\n",
    "        model_path = Path(self.config.updated_base_model)\n",
    "\n",
    "        if not model_path.exists():\n",
    "            logger.error(f\"Could not find model at {model_path}. Run the Base Model pipeline stage first.\")\n",
    "            raise FileNotFoundError(f\"Could not find model at {model_path}. Run the Base Model pipeline stage first.\")\n",
    "        \n",
    "        try:\n",
    "            self.output_model = tf.keras.models.load_model(model_path)\n",
    "            logger.info(f\"Successfully loaded the base model from {model_path}.\")\n",
    "\n",
    "            # Enabling Eager Execution (optional in TF 2.x) due to library requirement\n",
    "            tf.config.run_functions_eagerly(True)\n",
    "\n",
    "            # Recompile model with a fresh optimizer (required after loading)\n",
    "            self.output_model.compile(\n",
    "                optimizer=self._get_optimizer(),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                metrics=[\"accuracy\"]\n",
    "            )\n",
    "            logger.info(f\"Successfully recomplied the model.\")\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while loading the update base model at {model_path}: {exception_error}\")\n",
    "            raise \n",
    "            \n",
    "    \n",
    "    def get_data_generators(self) -> None:\n",
    "        \"\"\"\n",
    "        Update train and validation data generators using ImageDataGenerator.\n",
    "        Applies augmentation only on training data if enabled.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(\"Preparing ImageDataGenerators...\")\n",
    "\n",
    "            train_datagen = ImageDataGenerator(rescale=1.0/255, **self.config.params_if_augmentation)\n",
    "            valid_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "            self.training_generator = self._build_generator(train_datagen, self.config.training_data, \"Train\")\n",
    "            self.valid_generator = self._build_generator(valid_datagen, self.config.validation_data, \"Valid\")\n",
    "\n",
    "            # Ensure class-to-index mapping is consistent\n",
    "            if self.training_generator.class_indices != self.valid_generator.class_indices:\n",
    "                logger.error(\"Mismatch in class indices between train and validation generators!\")\n",
    "                raise ValueError(\"Mismatch in class indices between train and validation generators!\")\n",
    "\n",
    "            logger.info(\"ImageDataGenerators created successfully.\")\n",
    "        \n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while creating data generators: {exception_error}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def train(self) -> None:\n",
    "        \"\"\"\n",
    "        Trains the model using prepared generators.\n",
    "        \"\"\"\n",
    "        if self.output_model == None:\n",
    "            logger.error(\"Base model not found. Run get_base_model() before calling train().\")\n",
    "            raise ValueError(\"Base model not found. Run get_base_model() before calling train().\")\n",
    "        \n",
    "        if (self.config.params_checkpoint) and (not self.checkpoint_path.exists()) and (self.config.params_epochs >= 1):\n",
    "            self._create_checkpoint()\n",
    "\n",
    "        try:\n",
    "            logger.info(\"Initializing model training...\")\n",
    "\n",
    "            # Counting the images in each of the datasets\n",
    "            self.training_images = self._count_images_in_directory(self.config.training_data)\n",
    "            self.validation_images = self._count_images_in_directory(self.config.validation_data)\n",
    "\n",
    "            # Initializing the custom callback from tf.Keras\n",
    "            custom_callback = self._get_callbacks()\n",
    "\n",
    "            # Fitting the model\n",
    "            total_epochs = self.config.params_epochs + self.additional_epochs\n",
    "\n",
    "            self.output_model.fit(\n",
    "                self.training_generator,\n",
    "                validation_data=self.valid_generator,\n",
    "                initial_epoch=self.last_epoch,         # Sets starting point for correct logging\n",
    "                epochs=total_epochs,                        \n",
    "                steps_per_epoch=ceil(self.training_images / self.config.params_batch_size),\n",
    "                validation_steps=ceil(self.validation_images / self.config.params_batch_size),\n",
    "                callbacks=[custom_callback],\n",
    "                verbose=1\n",
    "            )\n",
    "    \n",
    "            # Updating number of epochs completed for resume train\n",
    "            self.last_epoch = total_epochs\n",
    "\n",
    "            logger.info(\"Successfully trained model based on provided parameters.\")\n",
    "            save_tf_model(save_path=self.config.trained_model_path, model=self.output_model)\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while training the model: {exception_error}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def resume_train(self, add_epochs: int) -> None:\n",
    "        \"\"\"\n",
    "        Resumes model training for additional number of epochs.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if self.additional_epochs == None:\n",
    "                self.additional_epochs = 0\n",
    "            self.additional_epochs += add_epochs\n",
    "\n",
    "            self.train()\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while resuming training: {exception_error}\")\n",
    "            raise\n",
    "    \n",
    "\n",
    "    def save_class_indices(self) -> None:\n",
    "        \"\"\"\n",
    "        Saves the class index mapping as a JSON file for future reference.\n",
    "        \"\"\"\n",
    "        if self.training_generator == None:\n",
    "            logger.error(\"Class indices not found. Run get_data_generators() before calling save_class_indices().\")\n",
    "            raise ValueError(\"Class indices not found. Run get_data_generators() before calling save_class_indices().\")\n",
    "\n",
    "        try:\n",
    "            save_path = Path(self.config.root_dir / \"class_indices.json\")\n",
    "            save_json(save_path=save_path, data=self.training_generator.class_indices)\n",
    "\n",
    "            if self.config.params_checkpoint and self.checkpoint_path.exists():\n",
    "                checkpoint_save_path = Path(self.checkpoint_path / \"class_indices.json\")\n",
    "                save_json(save_path=checkpoint_save_path, data=self.training_generator.class_indices)\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while saving class indices: {exception_error}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def _build_generator(self, datagen: ImageDataGenerator, data_path: Union[str, Path], tag: str) -> DirectoryIterator:\n",
    "        \"\"\"\n",
    "        Helper to build a flow_from_directory generator with consistent options.\n",
    "\n",
    "        Args:\n",
    "        - datagen (ImageDataGenerator): Instance of the ImageDataGenerator.\n",
    "        - data_path (Union[str, Path]): Path to the directory containing images.\n",
    "        - tag (str): Label for logging context (\"Train\" or \"Valid\").\n",
    "\n",
    "        Returns:\n",
    "        - DirectoryIterator: Configured Keras generator for the given directory.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data_path = Path(data_path)\n",
    "\n",
    "            if not data_path.exists():\n",
    "                logger.error(f\"{tag.title()} directory not found: {data_path}\")\n",
    "                raise FileNotFoundError(f\"{tag.title()} directory not found: {data_path}\")\n",
    "\n",
    "            # Building generator\n",
    "            generator_unit = datagen.flow_from_directory(\n",
    "                directory=data_path,\n",
    "                target_size=self.config.params_image_size[:2],\n",
    "                batch_size=self.config.params_batch_size,\n",
    "                class_mode=\"categorical\",\n",
    "                shuffle=True,\n",
    "            )\n",
    "\n",
    "            return generator_unit\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while build generator: {exception_error}\")\n",
    "            raise\n",
    "    \n",
    "\n",
    "    def _get_callbacks(self) -> list[Callback]:\n",
    "        \"\"\"\n",
    "        Constructs and returns a list of Keras-compatible callbacks based on config settings.\n",
    "\n",
    "        Returns:\n",
    "            List[Callback]: A list of callbacks to be used during model training.\n",
    "\n",
    "        Handles:\n",
    "        - Checkpointing the model if 'params_checkpoint' is True.\n",
    "        - Logging to MLflow via DagsHub if 'params_mlflow' is True.\n",
    "        \"\"\"\n",
    "        custom_callback = []\n",
    "\n",
    "        # Add checkpoint callback if enabled in config\n",
    "        try:\n",
    "            if self.config.params_checkpoint:\n",
    "                custom_callback.append(CheckpointCallback(save_directory=self.checkpoint_path, model_to_save=self.output_model))\n",
    "        \n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while loading the checkpoint callback: {exception_error}\")\n",
    "\n",
    "        # Add MLflow callback if enabled in config\n",
    "        try:\n",
    "            if self.config.params_mlflow:\n",
    "                dagshub.init(repo_owner=\"Vish501\", repo_name=\"TumorTracer\", mlflow=True)\n",
    "                custom_callback.append(MLflowCallback(config=self.config, checkpoint_path=self.checkpoint_path))\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while loading the MLflow callback: {exception_error}\")                \n",
    "\n",
    "        return custom_callback\n",
    "\n",
    "\n",
    "    def _create_checkpoint(self) -> None:\n",
    "        \"\"\"\n",
    "        Creates a checkpoint directory and saves the training configuration as a JSON file.\n",
    "\n",
    "        Purpose:\n",
    "        - Ensures the checkpoint directory exists.\n",
    "        - Saves the current training configuration (hyperparameters) used in that run.\n",
    "        - Helps with reproducibility and traceability for saved models.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(\"Creating checkpoint directory...\")\n",
    "\n",
    "            save_path = Path(self.checkpoint_path / \"params_used.json\")\n",
    "            create_directories([self.checkpoint_path])\n",
    "\n",
    "            # Convert all Path objects to str recursively\n",
    "            config_dict = convert_paths_to_str(asdict(self.config))\n",
    "\n",
    "            save_json(save_path=save_path, data=config_dict)\n",
    "            \n",
    "            logger.info(f\"Checkpoint directory created.\")\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while creating checkpoint directroy: {exception_error}\")\n",
    "            raise \n",
    "\n",
    "\n",
    "    def _get_optimizer(self) -> tf.keras.optimizers.Optimizer:\n",
    "        \"\"\"\n",
    "        Dynamically selects and returns a TensorFlow optimizer based on the configuration.\n",
    "\n",
    "        Returns:\n",
    "            tf.keras.optimizers.Optimizer: Configured optimizer instance for model compilation.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Normalize optimizer name to lowercase for consistent matching\n",
    "            optimizer_name = self.config.params_optimizer.strip().upper()\n",
    "            optimizer = None\n",
    "\n",
    "            # Select optimizer based on configuration\n",
    "            if optimizer_name == \"SGD\":\n",
    "                optimizer = tf.keras.optimizers.SGD(learning_rate=self.config.params_learning_rate)\n",
    "\n",
    "            elif optimizer_name == \"RMSPROP\":\n",
    "                optimizer = tf.keras.optimizers.RMSprop(learning_rate=self.config.params_learning_rate) \n",
    "\n",
    "            else:\n",
    "                # Default to Adam if unsupported optimizer name is provided\n",
    "                if optimizer_name != \"ADAM\":\n",
    "                    logger.info(f\"Unsupported optimizer name {optimizer_name} provided. Falling back to 'Adam'.\")\n",
    "                    optimizer_name = \"ADAM\"\n",
    "\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate=self.config.params_learning_rate)\n",
    "\n",
    "            logger.info(f\"Optimizer '{optimizer_name}' initialized and returned.\")\n",
    "            return optimizer\n",
    "        \n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while loading optimizer: {exception_error}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _count_images_in_directory(directory_path: Union[str, Path]) -> int:\n",
    "        \"\"\"\n",
    "        Counts the total number of image files in a directory and its subfolders.\n",
    "\n",
    "        Args:\n",
    "        - directory_path (str or Path): Path to the dataset root (e.g., train or valid)\n",
    "\n",
    "        Returns:\n",
    "        - int: Total number of images found\n",
    "        \"\"\"\n",
    "        try:\n",
    "            directory_path = Path(directory_path)\n",
    "            total_images = 0\n",
    "\n",
    "            if not directory_path.exists():\n",
    "                logger.error(f\"Could not find the path {directory_path}\")\n",
    "                raise FileNotFoundError(f\"Could not find the path {directory_path}\")\n",
    "            \n",
    "            for _, _, files in os.walk(directory_path):\n",
    "                total_images += len([f for f in files if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
    "\n",
    "            if total_images == 0:\n",
    "                logger.error(f\"No images found in {directory_path}\")\n",
    "                raise ValueError(f\"No images found in {directory_path}\")       \n",
    "\n",
    "            return total_images\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while counting images in directory: {exception_error}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d1c24ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=4, connect=5, read=4, redirect=5, status=5)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='dagshub.com', port=443): Read timed out. (read timeout=120)\")': /Vish501/TumorTracer.mlflow/api/2.0/mlflow/runs/update\n"
     ]
    }
   ],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c134e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-06 19:26:46,149: INFO: common: YAML file: config/config.yaml loaded successfully]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:YAML file: config/config.yaml loaded successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-06 19:26:46,160: INFO: common: YAML file: params/params.yaml loaded successfully]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:YAML file: params/params.yaml loaded successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-06 19:26:46,163: INFO: 234186428: Loading configuration from config/config.yaml and parameters from params/params.yaml]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Loading configuration from config/config.yaml and parameters from params/params.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-06 19:26:46,165: INFO: common: Directory: artifacts created successfully.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Directory: artifacts created successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-06 19:26:46,166: INFO: common: Directory: artifacts/model_training created successfully.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Directory: artifacts/model_training created successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-06 19:26:46,167: INFO: 234186428: ModelTrainingConfig created with: ModelTrainingConfig(root_dir=PosixPath('artifacts/model_training'), trained_model_path=PosixPath('artifacts/model_training/trained_model.h5'), updated_base_model=PosixPath('artifacts/base_model/updated_base_model.h5'), training_data=PosixPath('artifacts/data_ingestion/Data/train'), validation_data=PosixPath('artifacts/data_ingestion/Data/valid'), params_augmentation=True, params_checkpoint=True, params_mlflow=True, params_image_size=(224, 224, 3), params_batch_size=16, params_epochs=2, params_optimizer='Adam', params_learning_rate=0.01, params_if_augmentation={'rotation_range': 15, 'width_shift_range': 0.1, 'height_shift_range': 0.1, 'shear_range': 0.1, 'zoom_range': 0.2, 'horizontal_flip': True, 'fill_mode': 'nearest'})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:ModelTrainingConfig created with: ModelTrainingConfig(root_dir=PosixPath('artifacts/model_training'), trained_model_path=PosixPath('artifacts/model_training/trained_model.h5'), updated_base_model=PosixPath('artifacts/base_model/updated_base_model.h5'), training_data=PosixPath('artifacts/data_ingestion/Data/train'), validation_data=PosixPath('artifacts/data_ingestion/Data/valid'), params_augmentation=True, params_checkpoint=True, params_mlflow=True, params_image_size=(224, 224, 3), params_batch_size=16, params_epochs=2, params_optimizer='Adam', params_learning_rate=0.01, params_if_augmentation={'rotation_range': 15, 'width_shift_range': 0.1, 'height_shift_range': 0.1, 'shear_range': 0.1, 'zoom_range': 0.2, 'horizontal_flip': True, 'fill_mode': 'nearest'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-06 19:26:46,171: ERROR: 4197901811: Unexpected error while setting up MLFlow: Run with UUID 21227cf8ae6c4263b504a8863c5b0616 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:cnnClassifierLogger_running:Unexpected error while setting up MLFlow: Run with UUID 21227cf8ae6c4263b504a8863c5b0616 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-06 19:26:46,172: ERROR: 2758440419: Unexpected error during model training pipeline: Run with UUID 21227cf8ae6c4263b504a8863c5b0616 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True]\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2543/2758440419.py\", line 5, in <module>\n",
      "    with ModelTraining(config=training_config) as training_constructor:\n",
      "  File \"/tmp/ipykernel_2543/4197901811.py\", line 207, in __enter__\n",
      "    with mlflow.start_run(\"Train_Run\"):\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/mlflow/tracking/fluent.py\", line 306, in start_run\n",
      "    raise Exception(\n",
      "Exception: Run with UUID 21227cf8ae6c4263b504a8863c5b0616 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:cnnClassifierLogger_running:Unexpected error during model training pipeline: Run with UUID 21227cf8ae6c4263b504a8863c5b0616 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2543/2758440419.py\", line 5, in <module>\n",
      "    with ModelTraining(config=training_config) as training_constructor:\n",
      "  File \"/tmp/ipykernel_2543/4197901811.py\", line 207, in __enter__\n",
      "    with mlflow.start_run(\"Train_Run\"):\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/site-packages/mlflow/tracking/fluent.py\", line 306, in start_run\n",
      "    raise Exception(\n",
      "Exception: Run with UUID 21227cf8ae6c4263b504a8863c5b0616 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Run with UUID 21227cf8ae6c4263b504a8863c5b0616 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m config_manager = ConfigurationManager()\n\u001b[32m      3\u001b[39m training_config = config_manager.get_training_config()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mModelTraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtraining_constructor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_constructor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_base_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_constructor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_data_generators\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 207\u001b[39m, in \u001b[36mModelTraining.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.params_mlflow:\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTrain_Run\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m    208\u001b[39m             logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInitializing MLflow run\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/mlflow/tracking/fluent.py:306\u001b[39m, in \u001b[36mstart_run\u001b[39m\u001b[34m(run_id, experiment_id, run_name, nested, tags, description, log_system_metrics)\u001b[39m\n\u001b[32m    304\u001b[39m experiment_id = \u001b[38;5;28mstr\u001b[39m(experiment_id) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(experiment_id, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m experiment_id\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_active_run_stack) > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nested:\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[32m    307\u001b[39m         (\n\u001b[32m    308\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mRun with UUID \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m is already active. To start a new run, first end the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    309\u001b[39m             + \u001b[33m\"\u001b[39m\u001b[33mcurrent run with mlflow.end_run(). To start a nested \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    310\u001b[39m             + \u001b[33m\"\u001b[39m\u001b[33mrun, call start_run with nested=True\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    311\u001b[39m         ).format(_active_run_stack[\u001b[32m0\u001b[39m].info.run_id)\n\u001b[32m    312\u001b[39m     )\n\u001b[32m    313\u001b[39m client = MlflowClient()\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_id:\n",
      "\u001b[31mException\u001b[39m: Run with UUID 21227cf8ae6c4263b504a8863c5b0616 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config_manager = ConfigurationManager()\n",
    "    training_config = config_manager.get_training_config()\n",
    "\n",
    "    with ModelTraining(config=training_config) as training_constructor:\n",
    "        training_constructor.get_base_model()\n",
    "        training_constructor.get_data_generators()\n",
    "        training_constructor.train()\n",
    "        training_constructor.save_class_indices()\n",
    "        training_constructor.resume_train(add_epochs=2)\n",
    "\n",
    "except Exception as exception_error:\n",
    "    logger.exception(f\"Unexpected error during model training pipeline: {exception_error}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9432ddc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
