{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df151a0",
   "metadata": {},
   "source": [
    "# Environment Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "439fb644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/TumorTracer'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Loading environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Changing directory to main directory for easy data access\n",
    "working_directory = os.getenv(\"WORKING_DIRECTORY\")\n",
    "os.chdir(working_directory)\n",
    "\n",
    "# Checking the change\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a2b2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git folder exists: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Checking the change\n",
    "print(\"Git folder exists:\", Path(\".git\").exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e77ad8",
   "metadata": {},
   "source": [
    "# 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8554ae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from cnnClassifier import get_logger\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "# Initializing the logger\n",
    "logger = get_logger()\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainingConfig:\n",
    "    \"\"\"\n",
    "    Immutable configuration class to store all parameters \n",
    "    and paths required for model training. \n",
    "    \"\"\"\n",
    "    root_dir: Path                                          # Directory for training artifacts\n",
    "    trained_model_path: Path                                # Final model output path\n",
    "    updated_base_model: Path                                # Pretrained model with custom head\n",
    "    training_data: Path                                     # Directory with training images\n",
    "    validation_data: Path                                   # Directory with validation images\n",
    "    params_augmentation: bool                               # Whether to apply augmentation\n",
    "    params_image_size: tuple[int, int, int]                 # Input image size, e.g., [224, 224, 3]\n",
    "    params_batch_size: int                                  # Batch size for training\n",
    "    params_epochs: int                                      # Total epochs\n",
    "    params_learning_rate: float                             # Learning rate for training\n",
    "    params_if_augmentation: Optional[Dict[str, Any]] = None # Dict of augmentation hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d3dd096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories\n",
    "from cnnClassifier import get_logger\n",
    "\n",
    "# Initializing the logger\n",
    "logger = get_logger()\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self, config_file_path=CONFIG_FILE_PATH, params_file_path=PARAMS_FILE_PATH) -> None:\n",
    "        \"\"\"\n",
    "        Reads configuration files (config.yaml and params.yaml), \n",
    "        ensures necessary directories exist, and prepares structured config objects.\n",
    "\n",
    "        Args:\n",
    "        - config_file_path (str): Path to the config.yaml file.\n",
    "        - params_file_path (str): Path to the params.yaml file.\n",
    "        \"\"\"\n",
    "        # Validate and load config.yaml\n",
    "        if not Path(config_file_path).exists():\n",
    "            logger.error(f\"Config file not found at: {config_file_path}\")\n",
    "            raise FileNotFoundError(f\"Config file not found at: {config_file_path}\")\n",
    "        self.config = read_yaml(config_file_path)\n",
    "\n",
    "        # Validate and load params.yaml\n",
    "        if not Path(config_file_path).exists():\n",
    "            logger.error(f\"Params file not found at: {params_file_path}\")\n",
    "            raise FileNotFoundError(f\"Params file not found at: {params_file_path}\")\n",
    "        self.params = read_yaml(params_file_path)\n",
    "\n",
    "        logger.info(f\"Loading configuration from {config_file_path} and parameters from {params_file_path}\")\n",
    "\n",
    "        # Create the root artifacts directory (if not already present)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_training_config(self) -> ModelTrainingConfig:\n",
    "        \"\"\"\n",
    "        Prepares and returns the ModelTrainingConfig object.\n",
    "\n",
    "        Returns:\n",
    "        - ModelTrainingConfig: Structured config for training the updated base model.\n",
    "        \"\"\"\n",
    "        training_config = self.config.model_training\n",
    "        training_params = self.params.model_training\n",
    "\n",
    "        # Ensure the data_ingestion directory exists\n",
    "        create_directories([training_config.root_dir])\n",
    "\n",
    "        # Load augmentation params only if augmentation is enabled and params for it are present\n",
    "        params_for_augmentation = {}\n",
    "        if training_params.AUGMENTATION and hasattr(training_params, \"AUGMENTATION_PARAMS\"):\n",
    "            params_for_augmentation = dict(training_params.AUGMENTATION_PARAMS )\n",
    "\n",
    "        training_config = ModelTrainingConfig(\n",
    "            root_dir=Path(training_config.root_dir),\n",
    "            trained_model_path=Path(training_config.trained_model_path),\n",
    "            updated_base_model=Path(training_config.updated_model_path),\n",
    "            training_data=Path(training_config.training_dataset),\n",
    "            validation_data=Path(training_config.validation_dataset),\n",
    "            params_augmentation=training_params.AUGMENTATION,\n",
    "            params_image_size=tuple(training_params.IMAGE_SIZE),\n",
    "            params_batch_size=training_params.BATCH_SIZE,\n",
    "            params_epochs=training_params.EPOCHS,\n",
    "            params_learning_rate=training_params.LEARNING_RATE,\n",
    "            params_if_augmentation=params_for_augmentation,\n",
    "        )\n",
    "\n",
    "        logger.info(f\"ModelTrainingConfig created with: {training_config}\")\n",
    "\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a89a4f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 06:54:05.878007: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-04 06:54:08.661485: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-04 06:54:18.371703: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-04 06:54:27.218011: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from math import ceil\n",
    "from typing import Union\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from pathlib import Path\n",
    "\n",
    "from cnnClassifier.utils.common import create_directories, save_json\n",
    "from cnnClassifier import get_logger\n",
    "\n",
    "# Initializing the logger\n",
    "logger = get_logger()\n",
    "\n",
    "class ModelTraining:\n",
    "    \"\"\"\n",
    "    Initializes training pipeline with given configuration.\n",
    "    \"\"\"\n",
    "    def __init__(self, config: ModelTrainingConfig) -> None:\n",
    "        self.config = config\n",
    "        self.output_model = None\n",
    "        self.training_generator = None\n",
    "        self.valid_generator = None\n",
    "        self.training_images = None\n",
    "        self.validation_images = None\n",
    "    \n",
    "    \n",
    "    def get_base_model(self) -> None:\n",
    "        \"\"\"\n",
    "        Loads the base model form specified path.\n",
    "        \"\"\"\n",
    "        model_path = Path(self.config.updated_base_model)\n",
    "\n",
    "        if not model_path.exists():\n",
    "            logger.error(f\"Could not find model at {model_path}. Run the Base Model pipeline stage first.\")\n",
    "            raise FileNotFoundError(f\"Could not find model at {model_path}. Run the Base Model pipeline stage first.\")\n",
    "        \n",
    "        try:\n",
    "            self.output_model = tf.keras.models.load_model(model_path)\n",
    "            logger.info(f\"Successfully loaded the base model from {model_path}.\")\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while loading the update base model at {model_path}: {exception_error}\")\n",
    "            raise \n",
    "            \n",
    "    \n",
    "    def get_data_generators(self) -> None:\n",
    "        \"\"\"\n",
    "        Update train and validation data generators using ImageDataGenerator.\n",
    "        Applies augmentation only on training data if enabled.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(\"Preparing ImageDataGenerators...\")\n",
    "\n",
    "            train_datagen = ImageDataGenerator(rescale=1.0/255, **self.config.params_if_augmentation)\n",
    "            valid_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "            self.training_generator = self._build_generator(train_datagen, self.config.training_data, \"Train\")\n",
    "            self.valid_generator = self._build_generator(valid_datagen, self.config.validation_data, \"Valid\")\n",
    "\n",
    "            # Ensure class-to-index mapping is consistent\n",
    "            if self.training_generator.class_indices != self.valid_generator.class_indices:\n",
    "                logger.error(\"Mismatch in class indices between train and validation generators!\")\n",
    "                raise ValueError(\"Mismatch in class indices between train and validation generators!\")\n",
    "\n",
    "            logger.info(\"ImageDataGenerators created successfully.\")\n",
    "        \n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while creating data generators: {exception_error}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def train(self) -> None:\n",
    "        if self.output_model == None:\n",
    "            logger.error(\"Base model not found. Run get_base_model() before calling train().\")\n",
    "            raise ValueError(\"Base model not found. Run get_base_model() before calling train().\")\n",
    "        \n",
    "        try:\n",
    "            logger.info(\"Initializing model training...\")\n",
    "\n",
    "            # Enabling Eager Execution (optional in TF 2.x) due to library requirement\n",
    "            tf.config.run_functions_eagerly(True)\n",
    "\n",
    "            # Recompile model with a fresh optimizer (required after loading)\n",
    "            self.output_model.compile(\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=self.config.params_learning_rate),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                metrics=[\"accuracy\"]\n",
    "            )\n",
    "\n",
    "            # Counting the images in each of the datasets\n",
    "            self.training_images = self._count_images_in_directory(self.config.training_data)\n",
    "            self.validation_images = self._count_images_in_directory(self.config.validation_data)\n",
    "\n",
    "            # Fitting the model\n",
    "            self.output_model.fit(\n",
    "                self.training_generator,\n",
    "                validation_data=self.valid_generator,\n",
    "                epochs=self.config.params_epochs,\n",
    "                steps_per_epoch=ceil(self.training_images / self.config.params_batch_size),\n",
    "                validation_steps=ceil(self.validation_images / self.config.params_batch_size),\n",
    "            )\n",
    "        \n",
    "            logger.info(\"Successfully trained model based on provided parameters.\")\n",
    "\n",
    "            self._save_model(save_path=self.config.trained_model_path, model=self.output_model)\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while training the model: {exception_error}\")\n",
    "            raise\n",
    "\n",
    "    \n",
    "    def save_class_indices(self) -> None:\n",
    "        \"\"\"\n",
    "        Saves the class index mapping as a JSON file for future reference.\n",
    "        \"\"\"\n",
    "        if self.training_generator == None:\n",
    "            logger.error(\"Class indices not found. Run get_data_generators() before calling save_class_indices().\")\n",
    "            raise ValueError(\"Class indices not found. Run get_data_generators() before calling save_class_indices().\")\n",
    "\n",
    "        try:\n",
    "            save_path = Path(self.config.root_dir / \"class_indices.json\")\n",
    "            save_json(save_path=save_path, data=self.training_generator.class_indices)\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while saving class indices: {exception_error}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def _build_generator(self, datagen: ImageDataGenerator, data_path: Union[str, Path], tag: str) -> None:\n",
    "        \"\"\"\n",
    "        Helper to build a flow_from_directory generator with consistent options.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data_path = Path(data_path)\n",
    "\n",
    "            if not data_path.exists():\n",
    "                logger.error(f\"{tag.title()} directory not found: {data_path}\")\n",
    "                raise FileNotFoundError(f\"{tag.title()} directory not found: {data_path}\")\n",
    "\n",
    "            # Building generator\n",
    "            generator_unit = datagen.flow_from_directory(\n",
    "                directory=data_path,\n",
    "                target_size=self.config.params_image_size[:2],\n",
    "                batch_size=self.config.params_batch_size,\n",
    "                class_mode=\"categorical\",\n",
    "                shuffle=True,\n",
    "            )\n",
    "\n",
    "            return generator_unit\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while build generator: {exception_error}\")\n",
    "            raise\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def _count_images_in_directory(directory_path: Union[str, Path]) -> int:\n",
    "        \"\"\"\n",
    "        Counts the total number of image files in a directory and its subfolders.\n",
    "\n",
    "        Args:\n",
    "        - directory_path (str or Path): Path to the dataset root (e.g., train or valid)\n",
    "\n",
    "        Returns:\n",
    "        - int: Total number of images found\n",
    "        \"\"\"\n",
    "        try:\n",
    "            directory_path = Path(directory_path)\n",
    "            total_images = 0\n",
    "\n",
    "            if not directory_path.exists():\n",
    "                logger.error(f\"Could not find the path {directory_path}\")\n",
    "                raise FileNotFoundError(f\"Could not find the path {directory_path}\")\n",
    "            \n",
    "            for _, _, files in os.walk(directory_path):\n",
    "                total_images += len([f for f in files if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
    "\n",
    "            if total_images == 0:\n",
    "                logger.error(f\"No images found in {directory_path}\")\n",
    "                raise ValueError(f\"No images found in {directory_path}\")       \n",
    "\n",
    "            return total_images\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while counting images in directory: {exception_error}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _save_model(save_path: Path, model: tf.keras.Model) -> None:\n",
    "        \"\"\"\n",
    "        Saves a given model to the specified path.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            create_directories([save_path.parent])\n",
    "            model.save(save_path)\n",
    "            logger.info(f\"Model saved at: {save_path}\")\n",
    "        \n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while saving the model at {save_path}: {exception_error}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09059d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 06:54:44,482: INFO: common: YAML file: config/config.yaml loaded successfully]\n",
      "[2025-07-04 06:54:44,902: INFO: common: YAML file: params.yaml loaded successfully]\n",
      "[2025-07-04 06:54:44,903: INFO: 3329300415: Loading configuration from config/config.yaml and parameters from params.yaml]\n",
      "[2025-07-04 06:54:44,971: INFO: common: Directory: artifacts created successfully.]\n",
      "[2025-07-04 06:54:44,972: INFO: common: Directory: artifacts/model_training created successfully.]\n",
      "[2025-07-04 06:54:44,974: INFO: 3329300415: ModelTrainingConfig created with: ModelTrainingConfig(root_dir=PosixPath('artifacts/model_training'), trained_model_path=PosixPath('artifacts/model_training/trained_model.h5'), updated_base_model=PosixPath('artifacts/base_model/updated_base_model.h5'), training_data=PosixPath('artifacts/data_ingestion/Data/train'), validation_data=PosixPath('artifacts/data_ingestion/Data/valid'), params_augmentation=True, params_image_size=(224, 224, 3), params_batch_size=16, params_epochs=5, params_learning_rate=0.01, params_if_augmentation={'rotation_range': 15, 'width_shift_range': 0.1, 'height_shift_range': 0.1, 'shear_range': 0.1, 'zoom_range': 0.2, 'horizontal_flip': True, 'fill_mode': 'nearest'})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 06:54:48,340: INFO: 1183082594: Successfully loaded the base model from artifacts/base_model/updated_base_model.h5.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Successfully loaded the base model from artifacts/base_model/updated_base_model.h5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 06:54:48,341: INFO: 1183082594: Preparing ImageDataGenerators...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Preparing ImageDataGenerators...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 613 images belonging to 4 classes.\n",
      "Found 72 images belonging to 4 classes.\n",
      "[2025-07-04 06:54:49,055: INFO: 1183082594: ImageDataGenerators created successfully.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:ImageDataGenerators created successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 06:54:49,059: INFO: 1183082594: Initializing model training...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Initializing model training...\n",
      "/home/codespace/.python/current/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n",
      "2025-07-04 06:54:52.948646: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 205520896 exceeds 10% of free system memory.\n",
      "2025-07-04 06:54:53.925039: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 205520896 exceeds 10% of free system memory.\n",
      "2025-07-04 06:54:54.091809: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 205520896 exceeds 10% of free system memory.\n",
      "2025-07-04 06:54:54.196338: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 205520896 exceeds 10% of free system memory.\n",
      "2025-07-04 06:54:55.182111: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 205520896 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m868s\u001b[0m 22s/step - accuracy: 0.3458 - loss: 13.3627 - val_accuracy: 0.5139 - val_loss: 5.0941\n",
      "Epoch 2/5\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m800s\u001b[0m 21s/step - accuracy: 0.5893 - loss: 5.4325 - val_accuracy: 0.6944 - val_loss: 2.4442\n",
      "Epoch 3/5\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m802s\u001b[0m 21s/step - accuracy: 0.7609 - loss: 1.4935 - val_accuracy: 0.8056 - val_loss: 1.6772\n",
      "Epoch 4/5\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m799s\u001b[0m 20s/step - accuracy: 0.8403 - loss: 1.0734 - val_accuracy: 0.8333 - val_loss: 1.7113\n",
      "Epoch 5/5\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m798s\u001b[0m 20s/step - accuracy: 0.7882 - loss: 1.7114 - val_accuracy: 0.6528 - val_loss: 5.4372\n",
      "[2025-07-04 08:02:38,408: INFO: 1183082594: Successfully trained model based on provided parameters.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Successfully trained model based on provided parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 08:02:38,410: INFO: common: Directory: artifacts/model_training created successfully.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_test:Directory: artifacts/model_training created successfully.\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 08:02:38,580: INFO: 1183082594: Model saved at: artifacts/model_training/trained_model.h5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Model saved at: artifacts/model_training/trained_model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 08:02:38,585: INFO: common: Directory: artifacts/model_training created successfully.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_test:Directory: artifacts/model_training created successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 08:02:38,589: INFO: common: JSON file saved at: artifacts/model_training/class_indices.json]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_test:JSON file saved at: artifacts/model_training/class_indices.json\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config_manager = ConfigurationManager()\n",
    "    training_config = config_manager.get_training_config()\n",
    "\n",
    "    training_constructor = ModelTraining(config=training_config)\n",
    "    training_constructor.get_base_model()\n",
    "    training_constructor.get_data_generators()\n",
    "    training_constructor.train()\n",
    "    training_constructor.save_class_indices()\n",
    "\n",
    "except Exception as exception_error:\n",
    "    logger.exception(f\"Unexpected error during model training pipeline: {exception_error}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
