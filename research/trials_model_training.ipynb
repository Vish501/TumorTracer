{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df151a0",
   "metadata": {},
   "source": [
    "# Environment Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "439fb644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/TumorTracer'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Loading environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Changing directory to main directory for easy data access\n",
    "working_directory = os.getenv(\"WORKING_DIRECTORY\")\n",
    "os.chdir(working_directory)\n",
    "\n",
    "# Checking the change\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25a2b2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git folder exists: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Checking the change\n",
    "print(\"Git folder exists:\", Path(\".git\").exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e77ad8",
   "metadata": {},
   "source": [
    "# 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8554ae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from cnnClassifier import get_logger\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "# Initializing the logger\n",
    "logger = get_logger()\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainingConfig:\n",
    "    \"\"\"\n",
    "    Immutable configuration class to store all parameters \n",
    "    and paths required for model training. \n",
    "    \"\"\"\n",
    "    root_dir: Path                                          # Directory for training artifacts\n",
    "    trained_model_path: Path                                # Final model output path\n",
    "    updated_base_model: Path                                # Pretrained model with custom head\n",
    "    training_data: Path                                     # Directory with training images\n",
    "    validation_data: Path                                   # Directory with validation images\n",
    "    params_augmentation: bool                               # Whether to apply augmentation\n",
    "    params_checkpoint: bool                                 # Whether created models need to be checkpointed\n",
    "    params_image_size: tuple[int, int, int]                 # Input image size, e.g., [224, 224, 3]\n",
    "    params_batch_size: int                                  # Batch size for training\n",
    "    params_epochs: int                                      # Total epochs\n",
    "    params_optimizer: str                                   # Optimizer to be used when recompling model\n",
    "    params_learning_rate: float                             # Learning rate for training\n",
    "    params_if_augmentation: Optional[Dict[str, Any]] = None # Dict of augmentation hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3dd096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories\n",
    "from cnnClassifier import get_logger\n",
    "\n",
    "# Initializing the logger\n",
    "logger = get_logger()\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self, config_file_path=CONFIG_FILE_PATH, params_file_path=PARAMS_FILE_PATH) -> None:\n",
    "        \"\"\"\n",
    "        Reads configuration files (config.yaml and params.yaml), \n",
    "        ensures necessary directories exist, and prepares structured config objects.\n",
    "\n",
    "        Args:\n",
    "        - config_file_path (str): Path to the config.yaml file.\n",
    "        - params_file_path (str): Path to the params.yaml file.\n",
    "        \"\"\"\n",
    "        # Validate and load config.yaml\n",
    "        if not Path(config_file_path).exists():\n",
    "            logger.error(f\"Config file not found at: {config_file_path}\")\n",
    "            raise FileNotFoundError(f\"Config file not found at: {config_file_path}\")\n",
    "        self.config = read_yaml(config_file_path)\n",
    "\n",
    "        # Validate and load params.yaml\n",
    "        if not Path(config_file_path).exists():\n",
    "            logger.error(f\"Params file not found at: {params_file_path}\")\n",
    "            raise FileNotFoundError(f\"Params file not found at: {params_file_path}\")\n",
    "        self.params = read_yaml(params_file_path)\n",
    "\n",
    "        logger.info(f\"Loading configuration from {config_file_path} and parameters from {params_file_path}\")\n",
    "\n",
    "        # Create the root artifacts directory (if not already present)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_training_config(self) -> ModelTrainingConfig:\n",
    "        \"\"\"\n",
    "        Prepares and returns the ModelTrainingConfig object.\n",
    "\n",
    "        Returns:\n",
    "        - ModelTrainingConfig: Structured config for training the updated base model.\n",
    "        \"\"\"\n",
    "        training_config = self.config.model_training\n",
    "        training_params = self.params.model_training\n",
    "\n",
    "        # Ensure the data_ingestion directory exists\n",
    "        create_directories([training_config.root_dir])\n",
    "\n",
    "        # Load augmentation params only if augmentation is enabled and params for it are present\n",
    "        params_for_augmentation = {}\n",
    "        if training_params.AUGMENTATION and hasattr(training_params, \"AUGMENTATION_PARAMS\"):\n",
    "            params_for_augmentation = dict(training_params.AUGMENTATION_PARAMS )\n",
    "\n",
    "        training_config = ModelTrainingConfig(\n",
    "            root_dir=Path(training_config.root_dir),\n",
    "            trained_model_path=Path(training_config.trained_model_path),\n",
    "            updated_base_model=Path(training_config.updated_model_path),\n",
    "            training_data=Path(training_config.training_dataset),\n",
    "            validation_data=Path(training_config.validation_dataset),\n",
    "            params_augmentation=training_params.AUGMENTATION,\n",
    "            params_checkpoint=training_params.CHECKPOINT,\n",
    "            params_image_size=tuple(training_params.IMAGE_SIZE),\n",
    "            params_batch_size=training_params.BATCH_SIZE,\n",
    "            params_epochs=training_params.EPOCHS,\n",
    "            params_optimizer=training_params.OPTIMIZER,\n",
    "            params_learning_rate=training_params.LEARNING_RATE,\n",
    "            params_if_augmentation=params_for_augmentation,\n",
    "        )\n",
    "\n",
    "        logger.info(f\"ModelTrainingConfig created with: {training_config}\")\n",
    "\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a4f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from math import ceil\n",
    "from typing import Union\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, DirectoryIterator\n",
    "from pathlib import Path\n",
    "from dataclasses import asdict\n",
    "from datetime import datetime\n",
    "\n",
    "from cnnClassifier.utils.common import create_directories, save_json\n",
    "from cnnClassifier import get_logger\n",
    "\n",
    "# Initializing the logger\n",
    "logger = get_logger()\n",
    "\n",
    "class ModelTraining:\n",
    "    \"\"\"\n",
    "    Initializes training pipeline with given configuration.\n",
    "\n",
    "    Core Responsibilities:\n",
    "    - Load a pre-defined base model from disk and recompile it with a fresh optimizer.\n",
    "    - Set up data generators for training and validation, with optional augmentation.\n",
    "    - Train the model across multiple epochs with optional checkpointing.\n",
    "    - Resume training from where it left off.\n",
    "    - Save class label mappings and model artifacts.\n",
    "\n",
    "    Public Methods:\n",
    "    - get_base_model(): Load and compile the pre-trained base model.\n",
    "    - get_data_generators(): Prepare train and validation data generators.\n",
    "    - train(): Train the model with checkpointing on best validation accuracy.\n",
    "    - resume_train(add_epochs): Continue training the model for additional epochs.\n",
    "    - save_class_indices(): Save class-to-index mapping as JSON for reproducibility.\n",
    "\n",
    "    Private Utilities:\n",
    "    - _build_generator(): Helper to construct data generators with standard settings.\n",
    "    - _create_checkpoint(): Creates a checkpoint directory and stores training metadata.\n",
    "    - _get_optimizer(): Returns optimizer based on config.\n",
    "    - _count_images_in_directory(): Utility to count image files recursively.\n",
    "    - _save_model(): Saves the model to disk at the given path.\n",
    "    \"\"\"\n",
    "    def __init__(self, config: ModelTrainingConfig) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the model training pipeline.\n",
    "\n",
    "        - Sets random seeds for reproducibility.\n",
    "        - Prepares internal attributes for managing training, checkpoints, and model state.\n",
    "        \"\"\"\n",
    "        # Store configuration\n",
    "        self.config = config\n",
    "\n",
    "        # Set random seeds\n",
    "        seed = self.config.params_seed if hasattr(self.config, \"params_seed\") else 1234\n",
    "        tf.random.set_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        # Initialize model and training attributes\n",
    "        self.output_model = None\n",
    "        self.training_generator = None\n",
    "        self.valid_generator = None\n",
    "        self.training_images = None\n",
    "        self.validation_images = None\n",
    "        self.last_epoch = 0\n",
    "        self.additional_epochs = 0\n",
    "        self.best_val_accuracy = 0\n",
    "\n",
    "        # Initialize checkpoint directory path with timestamp\n",
    "        curr_time = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "        self.checkpoint_path = Path(self.config.root_dir / f\"Checkpoint_{curr_time}\")\n",
    "\n",
    "\n",
    "    def get_base_model(self) -> None:\n",
    "        \"\"\"\n",
    "        Loads the base model form specified path.\n",
    "        \"\"\"\n",
    "        model_path = Path(self.config.updated_base_model)\n",
    "\n",
    "        if not model_path.exists():\n",
    "            logger.error(f\"Could not find model at {model_path}. Run the Base Model pipeline stage first.\")\n",
    "            raise FileNotFoundError(f\"Could not find model at {model_path}. Run the Base Model pipeline stage first.\")\n",
    "        \n",
    "        try:\n",
    "            self.output_model = tf.keras.models.load_model(model_path)\n",
    "            logger.info(f\"Successfully loaded the base model from {model_path}.\")\n",
    "\n",
    "            # Enabling Eager Execution (optional in TF 2.x) due to library requirement\n",
    "            tf.config.run_functions_eagerly(True)\n",
    "\n",
    "            # Recompile model with a fresh optimizer (required after loading)\n",
    "            self.output_model.compile(\n",
    "                optimizer=self._get_optimizer(),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                metrics=[\"accuracy\"]\n",
    "            )\n",
    "            logger.info(f\"Successfully recomplied the model.\")\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while loading the update base model at {model_path}: {exception_error}\")\n",
    "            raise \n",
    "            \n",
    "    \n",
    "    def get_data_generators(self) -> None:\n",
    "        \"\"\"\n",
    "        Update train and validation data generators using ImageDataGenerator.\n",
    "        Applies augmentation only on training data if enabled.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(\"Preparing ImageDataGenerators...\")\n",
    "\n",
    "            train_datagen = ImageDataGenerator(rescale=1.0/255, **self.config.params_if_augmentation)\n",
    "            valid_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "            self.training_generator = self._build_generator(train_datagen, self.config.training_data, \"Train\")\n",
    "            self.valid_generator = self._build_generator(valid_datagen, self.config.validation_data, \"Valid\")\n",
    "\n",
    "            # Ensure class-to-index mapping is consistent\n",
    "            if self.training_generator.class_indices != self.valid_generator.class_indices:\n",
    "                logger.error(\"Mismatch in class indices between train and validation generators!\")\n",
    "                raise ValueError(\"Mismatch in class indices between train and validation generators!\")\n",
    "\n",
    "            logger.info(\"ImageDataGenerators created successfully.\")\n",
    "        \n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while creating data generators: {exception_error}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def train(self) -> None:\n",
    "        \"\"\"\n",
    "        Trains the model using prepared generators.\n",
    "        \"\"\"\n",
    "        if self.output_model == None:\n",
    "            logger.error(\"Base model not found. Run get_base_model() before calling train().\")\n",
    "            raise ValueError(\"Base model not found. Run get_base_model() before calling train().\")\n",
    "        \n",
    "        if (self.config.params_checkpoint) and (not self.checkpoint_path.exists()) and (self.config.params_epochs >= 1):\n",
    "            self._create_checkpoint()\n",
    "        \n",
    "        try:\n",
    "            logger.info(\"Initializing model training...\")\n",
    "\n",
    "            # Counting the images in each of the datasets\n",
    "            self.training_images = self._count_images_in_directory(self.config.training_data)\n",
    "            self.validation_images = self._count_images_in_directory(self.config.validation_data)\n",
    "\n",
    "            # Fitting the model\n",
    "            for epoch in range(self.last_epoch+1, self.config.params_epochs + self.additional_epochs):\n",
    "                history = self.output_model.fit(\n",
    "                    self.training_generator,\n",
    "                    validation_data=self.valid_generator,\n",
    "                    initial_epoch=epoch,         # Sets starting point for correct logging\n",
    "                    epochs=epoch+1,              # Only running 1 epoch at a time\n",
    "                    steps_per_epoch=ceil(self.training_images / self.config.params_batch_size),\n",
    "                    validation_steps=ceil(self.validation_images / self.config.params_batch_size),\n",
    "                )\n",
    "\n",
    "                # Updating number of epochs completed\n",
    "                self.last_epoch = epoch + 1\n",
    "\n",
    "                if self.config.params_checkpoint:\n",
    "                    # Accessing accurary scores\n",
    "                    train_acc = history.history.get(\"accuracy\", [0])[0]\n",
    "                    val_acc = history.history.get(\"val_accuracy\", [0])[0]\n",
    "\n",
    "                    # If current model is better than prior best model, saving the model\n",
    "                    if val_acc > self.best_val_accuracy:\n",
    "                        self.best_val_accuracy = val_acc\n",
    "                        model_path = Path(self.checkpoint_path / f\"model_e{epoch+1:02d}_acc{train_acc:.4f}_vacc{val_acc:.4f}.h5\")\n",
    "                        self._save_model(save_path=model_path, model=self.output_model)\n",
    "                        logger.info(f\"Saved new best model at {model_path}\")\n",
    "\n",
    "            logger.info(\"Successfully trained model based on provided parameters.\")\n",
    "            self._save_model(save_path=self.config.trained_model_path, model=self.output_model)\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while training the model: {exception_error}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def resume_train(self, add_epochs: int) -> None:\n",
    "        \"\"\"\n",
    "        Resumes model training for additional number of epochs.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if self.additional_epochs == None:\n",
    "                self.additional_epochs = 0\n",
    "            self.additional_epochs += add_epochs\n",
    "\n",
    "            self.train()\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while resuming training: {exception_error}\")\n",
    "            raise\n",
    "    \n",
    "\n",
    "    def save_class_indices(self) -> None:\n",
    "        \"\"\"\n",
    "        Saves the class index mapping as a JSON file for future reference.\n",
    "        \"\"\"\n",
    "        if self.training_generator == None:\n",
    "            logger.error(\"Class indices not found. Run get_data_generators() before calling save_class_indices().\")\n",
    "            raise ValueError(\"Class indices not found. Run get_data_generators() before calling save_class_indices().\")\n",
    "\n",
    "        try:\n",
    "            save_path = Path(self.config.root_dir / \"class_indices.json\")\n",
    "            save_json(save_path=save_path, data=self.training_generator.class_indices)\n",
    "\n",
    "            if self.config.params_checkpoint and self.checkpoint_path.exists():\n",
    "                checkpoint_save_path = Path(self.checkpoint_path / \"class_indices.json\")\n",
    "                save_json(save_path=checkpoint_save_path, data=self.training_generator.class_indices)\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while saving class indices: {exception_error}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def _build_generator(self, datagen: ImageDataGenerator, data_path: Union[str, Path], tag: str) -> DirectoryIterator:\n",
    "        \"\"\"\n",
    "        Helper to build a flow_from_directory generator with consistent options.\n",
    "\n",
    "        Args:\n",
    "        - datagen (ImageDataGenerator): Instance of the ImageDataGenerator.\n",
    "        - data_path (Union[str, Path]): Path to the directory containing images.\n",
    "        - tag (str): Label for logging context (\"Train\" or \"Valid\").\n",
    "\n",
    "        Returns:\n",
    "        - DirectoryIterator: Configured Keras generator for the given directory.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data_path = Path(data_path)\n",
    "\n",
    "            if not data_path.exists():\n",
    "                logger.error(f\"{tag.title()} directory not found: {data_path}\")\n",
    "                raise FileNotFoundError(f\"{tag.title()} directory not found: {data_path}\")\n",
    "\n",
    "            # Building generator\n",
    "            generator_unit = datagen.flow_from_directory(\n",
    "                directory=data_path,\n",
    "                target_size=self.config.params_image_size[:2],\n",
    "                batch_size=self.config.params_batch_size,\n",
    "                class_mode=\"categorical\",\n",
    "                shuffle=True,\n",
    "            )\n",
    "\n",
    "            return generator_unit\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while build generator: {exception_error}\")\n",
    "            raise\n",
    "    \n",
    "\n",
    "    def _create_checkpoint(self) -> None:\n",
    "        \"\"\"\n",
    "        Creates a checkpoint directory and saves the training configuration as a JSON file.\n",
    "\n",
    "        Purpose:\n",
    "        - Ensures the checkpoint directory exists.\n",
    "        - Saves the current training configuration (hyperparameters) used in that run.\n",
    "        - Helps with reproducibility and traceability for saved models.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(\"Creating checkpoint directory...\")\n",
    "\n",
    "            save_path = Path(self.checkpoint_path / \"params_used.json\")\n",
    "            create_directories([self.checkpoint_path])\n",
    "            save_json(save_path=save_path, data=asdict(self.config))\n",
    "            \n",
    "            logger.info(f\"Checkpoint directory created.\")\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while creating checkpoint directroy: {exception_error}\")\n",
    "            raise \n",
    "\n",
    "\n",
    "    def _get_optimizer(self) -> tf.keras.optimizers.Optimizer:\n",
    "        \"\"\"\n",
    "        Dynamically selects and returns a TensorFlow optimizer based on the configuration.\n",
    "\n",
    "        Returns:\n",
    "            tf.keras.optimizers.Optimizer: Configured optimizer instance for model compilation.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Normalize optimizer name to lowercase for consistent matching\n",
    "            optimizer_name = self.config.params_optimizer.strip().upper()\n",
    "            optimizer = None\n",
    "\n",
    "            # Select optimizer based on configuration\n",
    "            if optimizer_name == \"SGD\":\n",
    "                optimizer = tf.keras.optimizers.SGD(learning_rate=self.config.params_learning_rate)\n",
    "\n",
    "            elif optimizer_name == \"RMSPROP\":\n",
    "                optimizer = tf.keras.optimizers.RMSprop(learning_rate=self.config.params_learning_rate) \n",
    "\n",
    "            else:\n",
    "                # Default to Adam if unsupported optimizer name is provided\n",
    "                if optimizer_name != \"ADAM\":\n",
    "                    logger.info(f\"Unsupported optimizer name {optimizer_name} provided. Falling back to 'Adam'.\")\n",
    "                    optimizer_name = \"ADAM\"\n",
    "\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate=self.config.params_learning_rate)\n",
    "\n",
    "            logger.info(f\"Optimizer '{optimizer_name}' initialized and returned.\")\n",
    "            return optimizer\n",
    "        \n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while loading optimizer: {exception_error}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _count_images_in_directory(directory_path: Union[str, Path]) -> int:\n",
    "        \"\"\"\n",
    "        Counts the total number of image files in a directory and its subfolders.\n",
    "\n",
    "        Args:\n",
    "        - directory_path (str or Path): Path to the dataset root (e.g., train or valid)\n",
    "\n",
    "        Returns:\n",
    "        - int: Total number of images found\n",
    "        \"\"\"\n",
    "        try:\n",
    "            directory_path = Path(directory_path)\n",
    "            total_images = 0\n",
    "\n",
    "            if not directory_path.exists():\n",
    "                logger.error(f\"Could not find the path {directory_path}\")\n",
    "                raise FileNotFoundError(f\"Could not find the path {directory_path}\")\n",
    "            \n",
    "            for _, _, files in os.walk(directory_path):\n",
    "                total_images += len([f for f in files if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
    "\n",
    "            if total_images == 0:\n",
    "                logger.error(f\"No images found in {directory_path}\")\n",
    "                raise ValueError(f\"No images found in {directory_path}\")       \n",
    "\n",
    "            return total_images\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while counting images in directory: {exception_error}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _save_model(save_path: Path, model: tf.keras.Model) -> None:\n",
    "        \"\"\"\n",
    "        Saves a given model to the specified path.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            create_directories([save_path.parent])\n",
    "            model.save(save_path)\n",
    "            logger.info(f\"Model saved at: {save_path}\")\n",
    "        \n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while saving the model at {save_path}: {exception_error}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09059d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 11:51:49,326: INFO: common: YAML file: config/config.yaml loaded successfully]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_test:YAML file: config/config.yaml loaded successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 11:51:49,332: INFO: common: YAML file: params.yaml loaded successfully]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_test:YAML file: params.yaml loaded successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 11:51:49,334: INFO: 1535873039: Loading configuration from config/config.yaml and parameters from params.yaml]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Loading configuration from config/config.yaml and parameters from params.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 11:51:49,335: INFO: common: Directory: artifacts created successfully.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_test:Directory: artifacts created successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 11:51:49,337: INFO: common: Directory: artifacts/model_training created successfully.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_test:Directory: artifacts/model_training created successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 11:51:49,339: INFO: 1535873039: ModelTrainingConfig created with: ModelTrainingConfig(root_dir=PosixPath('artifacts/model_training'), trained_model_path=PosixPath('artifacts/model_training/trained_model.h5'), updated_base_model=PosixPath('artifacts/base_model/updated_base_model.h5'), training_data=PosixPath('artifacts/data_ingestion/Data/train'), validation_data=PosixPath('artifacts/data_ingestion/Data/valid'), params_augmentation=True, params_checkpoint=True, params_image_size=(224, 224, 3), params_batch_size=16, params_epochs=2, params_learning_rate=0.01, params_if_augmentation={'rotation_range': 15, 'width_shift_range': 0.1, 'height_shift_range': 0.1, 'shear_range': 0.1, 'zoom_range': 0.2, 'horizontal_flip': True, 'fill_mode': 'nearest'})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:ModelTrainingConfig created with: ModelTrainingConfig(root_dir=PosixPath('artifacts/model_training'), trained_model_path=PosixPath('artifacts/model_training/trained_model.h5'), updated_base_model=PosixPath('artifacts/base_model/updated_base_model.h5'), training_data=PosixPath('artifacts/data_ingestion/Data/train'), validation_data=PosixPath('artifacts/data_ingestion/Data/valid'), params_augmentation=True, params_checkpoint=True, params_image_size=(224, 224, 3), params_batch_size=16, params_epochs=2, params_learning_rate=0.01, params_if_augmentation={'rotation_range': 15, 'width_shift_range': 0.1, 'height_shift_range': 0.1, 'shear_range': 0.1, 'zoom_range': 0.2, 'horizontal_flip': True, 'fill_mode': 'nearest'})\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 11:51:49,550: INFO: 1475348133: Successfully loaded the base model from artifacts/base_model/updated_base_model.h5.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Successfully loaded the base model from artifacts/base_model/updated_base_model.h5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 11:51:49,554: INFO: 1475348133: Successfully recomplied the model.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Successfully recomplied the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 11:51:49,555: INFO: 1475348133: Preparing ImageDataGenerators...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Preparing ImageDataGenerators...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 613 images belonging to 4 classes.\n",
      "Found 72 images belonging to 4 classes.\n",
      "[2025-07-04 11:51:49,585: INFO: 1475348133: ImageDataGenerators created successfully.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:ImageDataGenerators created successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 11:51:49,586: INFO: 1475348133: Initializing model training...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Initializing model training...\n",
      "/home/codespace/.python/current/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "/home/codespace/.python/current/lib/python3.12/site-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n",
      "2025-07-04 11:51:50.272889: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 64225280 exceeds 10% of free system memory.\n",
      "2025-07-04 11:51:50.504491: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 64225280 exceeds 10% of free system memory.\n",
      "2025-07-04 11:51:50.576562: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 64225280 exceeds 10% of free system memory.\n",
      "2025-07-04 11:51:50.605378: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 64225280 exceeds 10% of free system memory.\n",
      "2025-07-04 11:51:50.918222: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 64225280 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m808s\u001b[0m 21s/step - accuracy: 0.3820 - loss: 18.9988 - val_accuracy: 0.4722 - val_loss: 8.2455\n",
      "[2025-07-04 12:05:17,983: INFO: common: Directory: artifacts/model_training/Checkpoint_%(asctime)s created successfully.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_test:Directory: artifacts/model_training/Checkpoint_%(asctime)s created successfully.\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 12:05:18,080: INFO: 1475348133: Model saved at: artifacts/model_training/Checkpoint_%(asctime)s/model_e01_acc0.4551_vacc0.4722.h5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Model saved at: artifacts/model_training/Checkpoint_%(asctime)s/model_e01_acc0.4551_vacc0.4722.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 12:05:18,082: INFO: 1475348133: Saved new best model at artifacts/model_training/Checkpoint_%(asctime)s/model_e01_acc0.4551_vacc0.4722.h5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Saved new best model at artifacts/model_training/Checkpoint_%(asctime)s/model_e01_acc0.4551_vacc0.4722.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m817s\u001b[0m 21s/step - accuracy: 0.6155 - loss: 4.7002 - val_accuracy: 0.6667 - val_loss: 2.1434\n",
      "[2025-07-04 12:18:55,425: INFO: common: Directory: artifacts/model_training/Checkpoint_%(asctime)s created successfully.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_test:Directory: artifacts/model_training/Checkpoint_%(asctime)s created successfully.\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 12:18:55,519: INFO: 1475348133: Model saved at: artifacts/model_training/Checkpoint_%(asctime)s/model_e02_acc0.6052_vacc0.6667.h5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Model saved at: artifacts/model_training/Checkpoint_%(asctime)s/model_e02_acc0.6052_vacc0.6667.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 12:18:55,523: INFO: 1475348133: Saved new best model at artifacts/model_training/Checkpoint_%(asctime)s/model_e02_acc0.6052_vacc0.6667.h5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Saved new best model at artifacts/model_training/Checkpoint_%(asctime)s/model_e02_acc0.6052_vacc0.6667.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 12:18:55,524: INFO: 1475348133: Successfully trained model based on provided parameters.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Successfully trained model based on provided parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 12:18:55,525: INFO: common: Directory: artifacts/model_training created successfully.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_test:Directory: artifacts/model_training created successfully.\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 12:18:55,700: INFO: 1475348133: Model saved at: artifacts/model_training/trained_model.h5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Model saved at: artifacts/model_training/trained_model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 12:18:55,702: INFO: common: Directory: artifacts/model_training created successfully.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_test:Directory: artifacts/model_training created successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 12:18:55,703: INFO: common: JSON file saved at: artifacts/model_training/class_indices.json]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_test:JSON file saved at: artifacts/model_training/class_indices.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 12:18:55,704: INFO: 1475348133: Initializing model training...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Initializing model training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m804s\u001b[0m 21s/step - accuracy: 0.7111 - loss: 3.7549 - val_accuracy: 0.7500 - val_loss: 3.0053\n",
      "[2025-07-04 12:33:18,043: INFO: common: Directory: artifacts/model_training/Checkpoint_%(asctime)s created successfully.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_test:Directory: artifacts/model_training/Checkpoint_%(asctime)s created successfully.\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 12:33:18,125: INFO: 1475348133: Model saved at: artifacts/model_training/Checkpoint_%(asctime)s/model_e02_acc0.7015_vacc0.7500.h5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Model saved at: artifacts/model_training/Checkpoint_%(asctime)s/model_e02_acc0.7015_vacc0.7500.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 12:33:18,127: INFO: 1475348133: Saved new best model at artifacts/model_training/Checkpoint_%(asctime)s/model_e02_acc0.7015_vacc0.7500.h5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Saved new best model at artifacts/model_training/Checkpoint_%(asctime)s/model_e02_acc0.7015_vacc0.7500.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m802s\u001b[0m 21s/step - accuracy: 0.7773 - loss: 1.8675 - val_accuracy: 0.6667 - val_loss: 4.3767\n",
      "Epoch 4/4\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m807s\u001b[0m 21s/step - accuracy: 0.7233 - loss: 2.7467 - val_accuracy: 0.7917 - val_loss: 2.4351\n",
      "[2025-07-04 13:00:07,413: INFO: common: Directory: artifacts/model_training/Checkpoint_%(asctime)s created successfully.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_test:Directory: artifacts/model_training/Checkpoint_%(asctime)s created successfully.\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 13:00:07,517: INFO: 1475348133: Model saved at: artifacts/model_training/Checkpoint_%(asctime)s/model_e04_acc0.7423_vacc0.7917.h5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Model saved at: artifacts/model_training/Checkpoint_%(asctime)s/model_e04_acc0.7423_vacc0.7917.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 13:00:07,521: INFO: 1475348133: Saved new best model at artifacts/model_training/Checkpoint_%(asctime)s/model_e04_acc0.7423_vacc0.7917.h5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Saved new best model at artifacts/model_training/Checkpoint_%(asctime)s/model_e04_acc0.7423_vacc0.7917.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 13:00:07,524: INFO: 1475348133: Successfully trained model based on provided parameters.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Successfully trained model based on provided parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 13:00:07,525: INFO: common: Directory: artifacts/model_training created successfully.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_test:Directory: artifacts/model_training created successfully.\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 13:00:07,741: INFO: 1475348133: Model saved at: artifacts/model_training/trained_model.h5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cnnClassifierLogger_running:Model saved at: artifacts/model_training/trained_model.h5\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config_manager = ConfigurationManager()\n",
    "    training_config = config_manager.get_training_config()\n",
    "\n",
    "    training_constructor = ModelTraining(config=training_config)\n",
    "    training_constructor.get_base_model()\n",
    "    training_constructor.get_data_generators()\n",
    "    training_constructor.train()\n",
    "    training_constructor.save_class_indices()\n",
    "    training_constructor.resume_train(add_epochs=1)\n",
    "\n",
    "except Exception as exception_error:\n",
    "    logger.exception(f\"Unexpected error during model training pipeline: {exception_error}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3066b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
