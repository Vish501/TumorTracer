{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc3a70d0",
   "metadata": {},
   "source": [
    "# Environment Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aecf789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/TumorTracer'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Loading environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Changing directory to main directory for easy data access\n",
    "working_directory = os.getenv(\"WORKING_DIRECTORY\")\n",
    "os.chdir(working_directory)\n",
    "\n",
    "# Checking the change\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc911ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git folder exists: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Checking the change\n",
    "print(\"Git folder exists:\", Path(\".git\").exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a926d5",
   "metadata": {},
   "source": [
    "# 1. Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71c7c7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from cnnClassifier import get_logger\n",
    "\n",
    "logger = get_logger()\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    \"\"\"\n",
    "    Immutable configuration class to hold all necessary paths \n",
    "    and dataset identifiers required for the data ingestion stage.\n",
    "    \"\"\"\n",
    "    root_dir: Path          # Base directory for all ingestion outputs\n",
    "    kaggle_dataset: str     # The Kaggle dataset identifier \"owner/dataset\"\n",
    "    download_zip: Path      # Path where the downloaded ZIP file will be saved\n",
    "    extracted_file: Path    # Path where the final extracted file will be stored\n",
    "    rename_map_yaml: Path   # Path where the dataset renaming file is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0233841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self, config_file_path=CONFIG_FILE_PATH, params_file_path=PARAMS_FILE_PATH) -> None:\n",
    "        \"\"\"\n",
    "        Reads configuration files (config.yaml and params.yaml), \n",
    "        ensures necessary directories exist, and prepares structured config objects.\n",
    "        \"\"\"\n",
    "        # Load both config and params YAML files into memory\n",
    "        if not Path(config_file_path):\n",
    "            logger.error(f\"Config file not found at: {config_file_path}\")\n",
    "            raise FileNotFoundError(f\"Config file not found at: {config_file_path}\")\n",
    "        else:\n",
    "            self.config = read_yaml(config_file_path)\n",
    "\n",
    "        if not Path(config_file_path):\n",
    "            logger.error(f\"Params file not found at: {params_file_path}\")\n",
    "            raise FileNotFoundError(f\"Params file not found at: {params_file_path}\")\n",
    "        else:\n",
    "            self.params = read_yaml(params_file_path)\n",
    "\n",
    "        logger.info(f\"Loading configuration from {config_file_path} and parameters from {params_file_path}\")\n",
    "\n",
    "        # Create the root artifacts directory (if not already present)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_ingestion_config(self) -> DataIngestionConfig:\n",
    "        \"\"\"\n",
    "        Creates and returns a DataIngestionConfig object with paths defined \n",
    "        for downloading and extracting the dataset.\n",
    "        \n",
    "        Returns:\n",
    "        - DataIngestionConfig: Structured config object for ingestion stage.\n",
    "        \"\"\"\n",
    "        config = self.config.data_ingestion\n",
    "\n",
    "        # Ensure the data_ingestion directory exists\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        # Build and return a structured configuration object for ingestion\n",
    "        ingestion_config = DataIngestionConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            kaggle_dataset=config.kaggle_dataset,\n",
    "            download_zip=Path(config.download_zip),\n",
    "            extracted_file=Path(config.extracted_file),\n",
    "            rename_map_yaml=Path(config.rename_map_yaml)\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"DataIngestionConfig created with: {ingestion_config}\")\n",
    "\n",
    "        return ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d04271fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-02 21:02:20,627: INFO: common: Directory: /home/codespace/.kaggle created successfully.]\n",
      "[2025-07-02 21:02:20,630: INFO: common: Directory: /home/codespace/.kaggle created successfully.]\n",
      "[2025-07-02 21:02:20,631: INFO: common: JSON file saved at: /home/codespace/.kaggle/kaggle.json]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from cnnClassifier.utils.common import create_directories, save_json\n",
    "\n",
    "def setup_kaggle_auth_from_secret(secret_env_var: str = \"KAGGLE_JSON\") -> None:\n",
    "    \"\"\"\n",
    "    Sets up Kaggle API authentication using a secret stored in an environment variable.\n",
    "\n",
    "    Parameters:\n",
    "    - secret_env_var (str): The name of the environment variable that contains\n",
    "                            the Kaggle credentials as a JSON string.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If the environment variable is missing or contains invalid JSON.\n",
    "    - Exception: For any other unhandled errors.\n",
    "    \"\"\"\n",
    "    # Read from environment variable (injected from Codespaces secret)\n",
    "    kaggle_json_str = os.getenv(secret_env_var)\n",
    "\n",
    "    if kaggle_json_str is None:\n",
    "        raise ValueError(f\"{secret_env_var} secret not found.\")\n",
    "    \n",
    "    try:\n",
    "        # Validate it's a proper JSON\n",
    "        kaggle_json_data = json.loads(kaggle_json_str)\n",
    "    except json.JSONDecodeError as exception:\n",
    "        raise ValueError(f\"{secret_env_var} does not contain valid JSON: {exception}\")\n",
    "\n",
    "    # Setting directory path\n",
    "    kaggle_dir = Path.home() / \".kaggle\"\n",
    "    kaggle_json_path = kaggle_dir / \"kaggle.json\"\n",
    "\n",
    "    try:\n",
    "        create_directories([kaggle_dir])\n",
    "        save_json(kaggle_json_path, kaggle_json_data)\n",
    "\n",
    "        # Set permissions\n",
    "        os.chmod(kaggle_json_path, 0o600)\n",
    "\n",
    "        # Set the environment variable explicitly for kaggle to pick up\n",
    "        os.environ[\"KAGGLE_CONFIG_DIR\"] = str(kaggle_dir)\n",
    "    \n",
    "    except Exception as exception:\n",
    "        raise exception\n",
    "    \n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "setup_kaggle_auth_from_secret()\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bbffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "import zipfile\n",
    "from box import ConfigBox\n",
    "from pathlib import Path\n",
    "from cnnClassifier.utils.common import read_yaml\n",
    "\n",
    "class DataIngestion:\n",
    "    \"\"\"\n",
    "    Handles the dataset ingestion step of the pipeline.\n",
    "\n",
    "    This includes:\n",
    "    - Downloading the dataset from Kaggle using the official Kaggle API\n",
    "    - Extracting the downloaded ZIP file to a specified directory\n",
    "    - Renaming class folders using a YAML-defined mapping\n",
    "\n",
    "    Attributes:\n",
    "    - config (DataIngestionConfig): Configuration object containing paths and dataset info\n",
    "\n",
    "    Public Methods:\n",
    "    - download_files(): Downloads the dataset zip file from Kaggle\n",
    "    - extract_files(): Extracts the zip file contents into the destination folder\n",
    "    - rename_class_folders_from_yaml(): Renames raw class folders based on a YAML mapping for provided folders\n",
    "\n",
    "    Private Methods:\n",
    "    - _load_renaming_file: Loads YAML file from location and returns it as ConfigBox\n",
    "    \"\"\"\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    def download_files(self) -> None:\n",
    "        \"\"\"\n",
    "        Downloads dataset from Kaggle using kaggle API.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            kaggle.api.dataset_download_files(\n",
    "                dataset=self.config.kaggle_dataset,\n",
    "                path=self.config.root_dir,\n",
    "                unzip=False\n",
    "            )\n",
    "\n",
    "            logger.info(f\"Successfully downloaded dataset {self.config.kaggle_dataset} at: {self.config.root_dir}\")\n",
    "\n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error file downloading dataset: {exception_error}\")\n",
    "            raise exception_error\n",
    "\n",
    "\n",
    "    def extract_files(self) -> None:\n",
    "        \"\"\"\n",
    "        Extracts the downloaded ZIP file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with zipfile.ZipFile(self.config.download_zip, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(self.config.root_dir)\n",
    "                logger.info(f\"Successfully extracted dataset {self.config.kaggle_dataset} at: {self.config.extracted_file}\")\n",
    "\n",
    "            if not self.config.extracted_file.exists():\n",
    "                logger.warning(f\"Expected file not found after extraction: {self.config.extracted_file}\")\n",
    "\n",
    "        except zipfile.BadZipFile:\n",
    "            logger.error(f\"Invalid zip file format.\")\n",
    "            raise\n",
    "        \n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error file unziping dataset: {exception_error}\")\n",
    "            raise\n",
    "\n",
    "    \n",
    "    def rename_class_folders_from_yaml(self) -> None:\n",
    "        \"\"\"\n",
    "        Renames raw class folders based on a YAML mapping for provided folders.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            renaming_map = self._load_renaming_file()\n",
    "\n",
    "            for folder, class_mapping in renaming_map.items():\n",
    "                current_path = self.config.extracted_file / folder\n",
    "\n",
    "                if not current_path.exists():\n",
    "                    logger.error(f\"While renaming could not find {folder} at: {current_path}\")\n",
    "                    continue\n",
    "                \n",
    "                for old_name, new_name in class_mapping.items():\n",
    "                    old_path = current_path / old_name\n",
    "                    new_path = current_path / new_name\n",
    "\n",
    "                    if new_path.exists():\n",
    "                        logger.error(f\"Target folder {new_name} already exists. Skipping rename.\")\n",
    "                        continue\n",
    "\n",
    "                    if not old_path.exists():\n",
    "                        logger.error(f\"Source folder missing: {old_path}\")\n",
    "                        continue\n",
    "\n",
    "                    old_path.rename(new_path)\n",
    "                    logger.info(f\"Successfully renamed '{old_name}' to '{new_path}' in {folder} folder.\")\n",
    "                    \n",
    "        except Exception as exception_error:\n",
    "            logger.error(f\"Unexpected error while renaming folders: {exception_error}\")\n",
    "            raise\n",
    "    \n",
    "    def _load_renaming_file(self) -> ConfigBox:\n",
    "        \"\"\"\n",
    "        Loads the folder renaming mapping file.\n",
    "\n",
    "        Returns:\n",
    "        - ConfigBox: YAML content with old-to-new folder name mappings.\n",
    "        \"\"\"\n",
    "        yaml_path = Path(self.config.rename_map_yaml)\n",
    "\n",
    "        if not yaml_path.exists():\n",
    "            logger.error(f\"Renaming YAML map not found at: {yaml_path}\")\n",
    "            raise FileNotFoundError(f\"Renaming YAML map not found at: {yaml_path}\")\n",
    "        return read_yaml(yaml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c1307a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-02 21:02:20,662: INFO: common: YAML file: config/config.yaml loaded successfully]\n",
      "[2025-07-02 21:02:20,665: INFO: common: YAML file: params.yaml loaded successfully]\n",
      "[2025-07-02 21:02:20,666: INFO: 1879874109: Loading configuration from config/config.yaml and parameters from params.yaml]\n",
      "[2025-07-02 21:02:20,671: INFO: common: Directory: artifacts created successfully.]\n",
      "[2025-07-02 21:02:20,672: INFO: common: Directory: artifacts/data_ingestion created successfully.]\n",
      "[2025-07-02 21:02:20,673: INFO: 1879874109: DataIngestionConfig created with: DataIngestionConfig(root_dir=PosixPath('artifacts/data_ingestion'), kaggle_dataset='mohamedhanyyy/chest-ctscan-images', download_zip=PosixPath('artifacts/data_ingestion/chest-ctscan-images.zip'), extracted_file=PosixPath('artifacts/data_ingestion/Data'), rename_map_yaml=PosixPath('config/class_name_map.yaml'))]\n",
      "Dataset URL: https://www.kaggle.com/datasets/mohamedhanyyy/chest-ctscan-images\n",
      "[2025-07-02 21:02:31,173: INFO: 2863922059: Successfully downloaded dataset mohamedhanyyy/chest-ctscan-images at: artifacts/data_ingestion]\n",
      "[2025-07-02 21:02:32,362: INFO: 2863922059: Successfully extracted dataset mohamedhanyyy/chest-ctscan-images at: artifacts/data_ingestion/Data]\n",
      "[2025-07-02 21:02:32,365: INFO: common: YAML file: config/class_name_map.yaml loaded successfully]\n",
      "[2025-07-02 21:02:32,366: INFO: 2863922059: Successfully renamed 'adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib' to 'artifacts/data_ingestion/Data/train/adenocarcinoma' in train folder.]\n",
      "[2025-07-02 21:02:32,366: INFO: 2863922059: Successfully renamed 'large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa' to 'artifacts/data_ingestion/Data/train/large_cell_carcinoma' in train folder.]\n",
      "[2025-07-02 21:02:32,368: INFO: 2863922059: Successfully renamed 'squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa' to 'artifacts/data_ingestion/Data/train/squamous_cell_carcinoma' in train folder.]\n",
      "[2025-07-02 21:02:32,369: ERROR: 2863922059: Target folder normal already exists. Skipping rename.]\n",
      "[2025-07-02 21:02:32,370: INFO: 2863922059: Successfully renamed 'adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib' to 'artifacts/data_ingestion/Data/valid/adenocarcinoma' in valid folder.]\n",
      "[2025-07-02 21:02:32,371: INFO: 2863922059: Successfully renamed 'large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa' to 'artifacts/data_ingestion/Data/valid/large_cell_carcinoma' in valid folder.]\n",
      "[2025-07-02 21:02:32,372: INFO: 2863922059: Successfully renamed 'squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa' to 'artifacts/data_ingestion/Data/valid/squamous_cell_carcinoma' in valid folder.]\n",
      "[2025-07-02 21:02:32,372: ERROR: 2863922059: Target folder normal already exists. Skipping rename.]\n",
      "[2025-07-02 21:02:32,373: ERROR: 2863922059: Target folder adenocarcinoma already exists. Skipping rename.]\n",
      "[2025-07-02 21:02:32,374: INFO: 2863922059: Successfully renamed 'large.cell.carcinoma' to 'artifacts/data_ingestion/Data/test/large_cell_carcinoma' in test folder.]\n",
      "[2025-07-02 21:02:32,375: INFO: 2863922059: Successfully renamed 'squamous.cell.carcinoma' to 'artifacts/data_ingestion/Data/test/squamous_cell_carcinoma' in test folder.]\n",
      "[2025-07-02 21:02:32,375: ERROR: 2863922059: Target folder normal already exists. Skipping rename.]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config_manager = ConfigurationManager()\n",
    "    ingestion_config = config_manager.get_ingestion_config()\n",
    "\n",
    "    data_ingestor = DataIngestion(config=ingestion_config)\n",
    "    data_ingestor.download_files()\n",
    "    data_ingestor.extract_files()\n",
    "    data_ingestor.rename_class_folders_from_yaml()\n",
    "\n",
    "except Exception as exception:\n",
    "    logger.exception(f\"Unexpected error during data ingestion pipeline: {exception}\")\n",
    "    raise exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729f881e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
